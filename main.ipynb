{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "\n",
    "from model import ResidualBlock, ResNet\n",
    "from train_eval_util import train, evaluate, calculate_accuracy, epoch_time\n",
    "from dataset import train_data, valid_data, test_data\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size= BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_iterator =  DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_iterator =  DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers: 110\n",
      "Total number of parameters: 1730714\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            432\n",
      "├─BatchNorm2d: 1-2                       32\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─ResidualBlock: 2-1                --\n",
      "|    |    └─Conv2d: 3-1                  2,304\n",
      "|    |    └─BatchNorm2d: 3-2             32\n",
      "|    |    └─Conv2d: 3-3                  2,304\n",
      "|    |    └─BatchNorm2d: 3-4             32\n",
      "|    |    └─Dropout: 3-5                 --\n",
      "|    |    └─Sequential: 3-6              --\n",
      "|    └─ResidualBlock: 2-2                --\n",
      "|    |    └─Conv2d: 3-7                  2,304\n",
      "|    |    └─BatchNorm2d: 3-8             32\n",
      "|    |    └─Conv2d: 3-9                  2,304\n",
      "|    |    └─BatchNorm2d: 3-10            32\n",
      "|    |    └─Dropout: 3-11                --\n",
      "|    |    └─Sequential: 3-12             --\n",
      "|    └─ResidualBlock: 2-3                --\n",
      "|    |    └─Conv2d: 3-13                 2,304\n",
      "|    |    └─BatchNorm2d: 3-14            32\n",
      "|    |    └─Conv2d: 3-15                 2,304\n",
      "|    |    └─BatchNorm2d: 3-16            32\n",
      "|    |    └─Dropout: 3-17                --\n",
      "|    |    └─Sequential: 3-18             --\n",
      "|    └─ResidualBlock: 2-4                --\n",
      "|    |    └─Conv2d: 3-19                 2,304\n",
      "|    |    └─BatchNorm2d: 3-20            32\n",
      "|    |    └─Conv2d: 3-21                 2,304\n",
      "|    |    └─BatchNorm2d: 3-22            32\n",
      "|    |    └─Dropout: 3-23                --\n",
      "|    |    └─Sequential: 3-24             --\n",
      "|    └─ResidualBlock: 2-5                --\n",
      "|    |    └─Conv2d: 3-25                 2,304\n",
      "|    |    └─BatchNorm2d: 3-26            32\n",
      "|    |    └─Conv2d: 3-27                 2,304\n",
      "|    |    └─BatchNorm2d: 3-28            32\n",
      "|    |    └─Dropout: 3-29                --\n",
      "|    |    └─Sequential: 3-30             --\n",
      "|    └─ResidualBlock: 2-6                --\n",
      "|    |    └─Conv2d: 3-31                 2,304\n",
      "|    |    └─BatchNorm2d: 3-32            32\n",
      "|    |    └─Conv2d: 3-33                 2,304\n",
      "|    |    └─BatchNorm2d: 3-34            32\n",
      "|    |    └─Dropout: 3-35                --\n",
      "|    |    └─Sequential: 3-36             --\n",
      "|    └─ResidualBlock: 2-7                --\n",
      "|    |    └─Conv2d: 3-37                 2,304\n",
      "|    |    └─BatchNorm2d: 3-38            32\n",
      "|    |    └─Conv2d: 3-39                 2,304\n",
      "|    |    └─BatchNorm2d: 3-40            32\n",
      "|    |    └─Dropout: 3-41                --\n",
      "|    |    └─Sequential: 3-42             --\n",
      "|    └─ResidualBlock: 2-8                --\n",
      "|    |    └─Conv2d: 3-43                 2,304\n",
      "|    |    └─BatchNorm2d: 3-44            32\n",
      "|    |    └─Conv2d: 3-45                 2,304\n",
      "|    |    └─BatchNorm2d: 3-46            32\n",
      "|    |    └─Dropout: 3-47                --\n",
      "|    |    └─Sequential: 3-48             --\n",
      "|    └─ResidualBlock: 2-9                --\n",
      "|    |    └─Conv2d: 3-49                 2,304\n",
      "|    |    └─BatchNorm2d: 3-50            32\n",
      "|    |    └─Conv2d: 3-51                 2,304\n",
      "|    |    └─BatchNorm2d: 3-52            32\n",
      "|    |    └─Dropout: 3-53                --\n",
      "|    |    └─Sequential: 3-54             --\n",
      "|    └─ResidualBlock: 2-10               --\n",
      "|    |    └─Conv2d: 3-55                 2,304\n",
      "|    |    └─BatchNorm2d: 3-56            32\n",
      "|    |    └─Conv2d: 3-57                 2,304\n",
      "|    |    └─BatchNorm2d: 3-58            32\n",
      "|    |    └─Dropout: 3-59                --\n",
      "|    |    └─Sequential: 3-60             --\n",
      "|    └─ResidualBlock: 2-11               --\n",
      "|    |    └─Conv2d: 3-61                 2,304\n",
      "|    |    └─BatchNorm2d: 3-62            32\n",
      "|    |    └─Conv2d: 3-63                 2,304\n",
      "|    |    └─BatchNorm2d: 3-64            32\n",
      "|    |    └─Dropout: 3-65                --\n",
      "|    |    └─Sequential: 3-66             --\n",
      "|    └─ResidualBlock: 2-12               --\n",
      "|    |    └─Conv2d: 3-67                 2,304\n",
      "|    |    └─BatchNorm2d: 3-68            32\n",
      "|    |    └─Conv2d: 3-69                 2,304\n",
      "|    |    └─BatchNorm2d: 3-70            32\n",
      "|    |    └─Dropout: 3-71                --\n",
      "|    |    └─Sequential: 3-72             --\n",
      "|    └─ResidualBlock: 2-13               --\n",
      "|    |    └─Conv2d: 3-73                 2,304\n",
      "|    |    └─BatchNorm2d: 3-74            32\n",
      "|    |    └─Conv2d: 3-75                 2,304\n",
      "|    |    └─BatchNorm2d: 3-76            32\n",
      "|    |    └─Dropout: 3-77                --\n",
      "|    |    └─Sequential: 3-78             --\n",
      "|    └─ResidualBlock: 2-14               --\n",
      "|    |    └─Conv2d: 3-79                 2,304\n",
      "|    |    └─BatchNorm2d: 3-80            32\n",
      "|    |    └─Conv2d: 3-81                 2,304\n",
      "|    |    └─BatchNorm2d: 3-82            32\n",
      "|    |    └─Dropout: 3-83                --\n",
      "|    |    └─Sequential: 3-84             --\n",
      "|    └─ResidualBlock: 2-15               --\n",
      "|    |    └─Conv2d: 3-85                 2,304\n",
      "|    |    └─BatchNorm2d: 3-86            32\n",
      "|    |    └─Conv2d: 3-87                 2,304\n",
      "|    |    └─BatchNorm2d: 3-88            32\n",
      "|    |    └─Dropout: 3-89                --\n",
      "|    |    └─Sequential: 3-90             --\n",
      "|    └─ResidualBlock: 2-16               --\n",
      "|    |    └─Conv2d: 3-91                 2,304\n",
      "|    |    └─BatchNorm2d: 3-92            32\n",
      "|    |    └─Conv2d: 3-93                 2,304\n",
      "|    |    └─BatchNorm2d: 3-94            32\n",
      "|    |    └─Dropout: 3-95                --\n",
      "|    |    └─Sequential: 3-96             --\n",
      "|    └─ResidualBlock: 2-17               --\n",
      "|    |    └─Conv2d: 3-97                 2,304\n",
      "|    |    └─BatchNorm2d: 3-98            32\n",
      "|    |    └─Conv2d: 3-99                 2,304\n",
      "|    |    └─BatchNorm2d: 3-100           32\n",
      "|    |    └─Dropout: 3-101               --\n",
      "|    |    └─Sequential: 3-102            --\n",
      "|    └─ResidualBlock: 2-18               --\n",
      "|    |    └─Conv2d: 3-103                2,304\n",
      "|    |    └─BatchNorm2d: 3-104           32\n",
      "|    |    └─Conv2d: 3-105                2,304\n",
      "|    |    └─BatchNorm2d: 3-106           32\n",
      "|    |    └─Dropout: 3-107               --\n",
      "|    |    └─Sequential: 3-108            --\n",
      "├─Sequential: 1-4                        --\n",
      "|    └─ResidualBlock: 2-19               --\n",
      "|    |    └─Conv2d: 3-109                4,608\n",
      "|    |    └─BatchNorm2d: 3-110           64\n",
      "|    |    └─Conv2d: 3-111                9,216\n",
      "|    |    └─BatchNorm2d: 3-112           64\n",
      "|    |    └─Dropout: 3-113               --\n",
      "|    |    └─Sequential: 3-114            576\n",
      "|    └─ResidualBlock: 2-20               --\n",
      "|    |    └─Conv2d: 3-115                9,216\n",
      "|    |    └─BatchNorm2d: 3-116           64\n",
      "|    |    └─Conv2d: 3-117                9,216\n",
      "|    |    └─BatchNorm2d: 3-118           64\n",
      "|    |    └─Dropout: 3-119               --\n",
      "|    |    └─Sequential: 3-120            --\n",
      "|    └─ResidualBlock: 2-21               --\n",
      "|    |    └─Conv2d: 3-121                9,216\n",
      "|    |    └─BatchNorm2d: 3-122           64\n",
      "|    |    └─Conv2d: 3-123                9,216\n",
      "|    |    └─BatchNorm2d: 3-124           64\n",
      "|    |    └─Dropout: 3-125               --\n",
      "|    |    └─Sequential: 3-126            --\n",
      "|    └─ResidualBlock: 2-22               --\n",
      "|    |    └─Conv2d: 3-127                9,216\n",
      "|    |    └─BatchNorm2d: 3-128           64\n",
      "|    |    └─Conv2d: 3-129                9,216\n",
      "|    |    └─BatchNorm2d: 3-130           64\n",
      "|    |    └─Dropout: 3-131               --\n",
      "|    |    └─Sequential: 3-132            --\n",
      "|    └─ResidualBlock: 2-23               --\n",
      "|    |    └─Conv2d: 3-133                9,216\n",
      "|    |    └─BatchNorm2d: 3-134           64\n",
      "|    |    └─Conv2d: 3-135                9,216\n",
      "|    |    └─BatchNorm2d: 3-136           64\n",
      "|    |    └─Dropout: 3-137               --\n",
      "|    |    └─Sequential: 3-138            --\n",
      "|    └─ResidualBlock: 2-24               --\n",
      "|    |    └─Conv2d: 3-139                9,216\n",
      "|    |    └─BatchNorm2d: 3-140           64\n",
      "|    |    └─Conv2d: 3-141                9,216\n",
      "|    |    └─BatchNorm2d: 3-142           64\n",
      "|    |    └─Dropout: 3-143               --\n",
      "|    |    └─Sequential: 3-144            --\n",
      "|    └─ResidualBlock: 2-25               --\n",
      "|    |    └─Conv2d: 3-145                9,216\n",
      "|    |    └─BatchNorm2d: 3-146           64\n",
      "|    |    └─Conv2d: 3-147                9,216\n",
      "|    |    └─BatchNorm2d: 3-148           64\n",
      "|    |    └─Dropout: 3-149               --\n",
      "|    |    └─Sequential: 3-150            --\n",
      "|    └─ResidualBlock: 2-26               --\n",
      "|    |    └─Conv2d: 3-151                9,216\n",
      "|    |    └─BatchNorm2d: 3-152           64\n",
      "|    |    └─Conv2d: 3-153                9,216\n",
      "|    |    └─BatchNorm2d: 3-154           64\n",
      "|    |    └─Dropout: 3-155               --\n",
      "|    |    └─Sequential: 3-156            --\n",
      "|    └─ResidualBlock: 2-27               --\n",
      "|    |    └─Conv2d: 3-157                9,216\n",
      "|    |    └─BatchNorm2d: 3-158           64\n",
      "|    |    └─Conv2d: 3-159                9,216\n",
      "|    |    └─BatchNorm2d: 3-160           64\n",
      "|    |    └─Dropout: 3-161               --\n",
      "|    |    └─Sequential: 3-162            --\n",
      "|    └─ResidualBlock: 2-28               --\n",
      "|    |    └─Conv2d: 3-163                9,216\n",
      "|    |    └─BatchNorm2d: 3-164           64\n",
      "|    |    └─Conv2d: 3-165                9,216\n",
      "|    |    └─BatchNorm2d: 3-166           64\n",
      "|    |    └─Dropout: 3-167               --\n",
      "|    |    └─Sequential: 3-168            --\n",
      "|    └─ResidualBlock: 2-29               --\n",
      "|    |    └─Conv2d: 3-169                9,216\n",
      "|    |    └─BatchNorm2d: 3-170           64\n",
      "|    |    └─Conv2d: 3-171                9,216\n",
      "|    |    └─BatchNorm2d: 3-172           64\n",
      "|    |    └─Dropout: 3-173               --\n",
      "|    |    └─Sequential: 3-174            --\n",
      "|    └─ResidualBlock: 2-30               --\n",
      "|    |    └─Conv2d: 3-175                9,216\n",
      "|    |    └─BatchNorm2d: 3-176           64\n",
      "|    |    └─Conv2d: 3-177                9,216\n",
      "|    |    └─BatchNorm2d: 3-178           64\n",
      "|    |    └─Dropout: 3-179               --\n",
      "|    |    └─Sequential: 3-180            --\n",
      "|    └─ResidualBlock: 2-31               --\n",
      "|    |    └─Conv2d: 3-181                9,216\n",
      "|    |    └─BatchNorm2d: 3-182           64\n",
      "|    |    └─Conv2d: 3-183                9,216\n",
      "|    |    └─BatchNorm2d: 3-184           64\n",
      "|    |    └─Dropout: 3-185               --\n",
      "|    |    └─Sequential: 3-186            --\n",
      "|    └─ResidualBlock: 2-32               --\n",
      "|    |    └─Conv2d: 3-187                9,216\n",
      "|    |    └─BatchNorm2d: 3-188           64\n",
      "|    |    └─Conv2d: 3-189                9,216\n",
      "|    |    └─BatchNorm2d: 3-190           64\n",
      "|    |    └─Dropout: 3-191               --\n",
      "|    |    └─Sequential: 3-192            --\n",
      "|    └─ResidualBlock: 2-33               --\n",
      "|    |    └─Conv2d: 3-193                9,216\n",
      "|    |    └─BatchNorm2d: 3-194           64\n",
      "|    |    └─Conv2d: 3-195                9,216\n",
      "|    |    └─BatchNorm2d: 3-196           64\n",
      "|    |    └─Dropout: 3-197               --\n",
      "|    |    └─Sequential: 3-198            --\n",
      "|    └─ResidualBlock: 2-34               --\n",
      "|    |    └─Conv2d: 3-199                9,216\n",
      "|    |    └─BatchNorm2d: 3-200           64\n",
      "|    |    └─Conv2d: 3-201                9,216\n",
      "|    |    └─BatchNorm2d: 3-202           64\n",
      "|    |    └─Dropout: 3-203               --\n",
      "|    |    └─Sequential: 3-204            --\n",
      "|    └─ResidualBlock: 2-35               --\n",
      "|    |    └─Conv2d: 3-205                9,216\n",
      "|    |    └─BatchNorm2d: 3-206           64\n",
      "|    |    └─Conv2d: 3-207                9,216\n",
      "|    |    └─BatchNorm2d: 3-208           64\n",
      "|    |    └─Dropout: 3-209               --\n",
      "|    |    └─Sequential: 3-210            --\n",
      "|    └─ResidualBlock: 2-36               --\n",
      "|    |    └─Conv2d: 3-211                9,216\n",
      "|    |    └─BatchNorm2d: 3-212           64\n",
      "|    |    └─Conv2d: 3-213                9,216\n",
      "|    |    └─BatchNorm2d: 3-214           64\n",
      "|    |    └─Dropout: 3-215               --\n",
      "|    |    └─Sequential: 3-216            --\n",
      "├─Sequential: 1-5                        --\n",
      "|    └─ResidualBlock: 2-37               --\n",
      "|    |    └─Conv2d: 3-217                18,432\n",
      "|    |    └─BatchNorm2d: 3-218           128\n",
      "|    |    └─Conv2d: 3-219                36,864\n",
      "|    |    └─BatchNorm2d: 3-220           128\n",
      "|    |    └─Dropout: 3-221               --\n",
      "|    |    └─Sequential: 3-222            2,176\n",
      "|    └─ResidualBlock: 2-38               --\n",
      "|    |    └─Conv2d: 3-223                36,864\n",
      "|    |    └─BatchNorm2d: 3-224           128\n",
      "|    |    └─Conv2d: 3-225                36,864\n",
      "|    |    └─BatchNorm2d: 3-226           128\n",
      "|    |    └─Dropout: 3-227               --\n",
      "|    |    └─Sequential: 3-228            --\n",
      "|    └─ResidualBlock: 2-39               --\n",
      "|    |    └─Conv2d: 3-229                36,864\n",
      "|    |    └─BatchNorm2d: 3-230           128\n",
      "|    |    └─Conv2d: 3-231                36,864\n",
      "|    |    └─BatchNorm2d: 3-232           128\n",
      "|    |    └─Dropout: 3-233               --\n",
      "|    |    └─Sequential: 3-234            --\n",
      "|    └─ResidualBlock: 2-40               --\n",
      "|    |    └─Conv2d: 3-235                36,864\n",
      "|    |    └─BatchNorm2d: 3-236           128\n",
      "|    |    └─Conv2d: 3-237                36,864\n",
      "|    |    └─BatchNorm2d: 3-238           128\n",
      "|    |    └─Dropout: 3-239               --\n",
      "|    |    └─Sequential: 3-240            --\n",
      "|    └─ResidualBlock: 2-41               --\n",
      "|    |    └─Conv2d: 3-241                36,864\n",
      "|    |    └─BatchNorm2d: 3-242           128\n",
      "|    |    └─Conv2d: 3-243                36,864\n",
      "|    |    └─BatchNorm2d: 3-244           128\n",
      "|    |    └─Dropout: 3-245               --\n",
      "|    |    └─Sequential: 3-246            --\n",
      "|    └─ResidualBlock: 2-42               --\n",
      "|    |    └─Conv2d: 3-247                36,864\n",
      "|    |    └─BatchNorm2d: 3-248           128\n",
      "|    |    └─Conv2d: 3-249                36,864\n",
      "|    |    └─BatchNorm2d: 3-250           128\n",
      "|    |    └─Dropout: 3-251               --\n",
      "|    |    └─Sequential: 3-252            --\n",
      "|    └─ResidualBlock: 2-43               --\n",
      "|    |    └─Conv2d: 3-253                36,864\n",
      "|    |    └─BatchNorm2d: 3-254           128\n",
      "|    |    └─Conv2d: 3-255                36,864\n",
      "|    |    └─BatchNorm2d: 3-256           128\n",
      "|    |    └─Dropout: 3-257               --\n",
      "|    |    └─Sequential: 3-258            --\n",
      "|    └─ResidualBlock: 2-44               --\n",
      "|    |    └─Conv2d: 3-259                36,864\n",
      "|    |    └─BatchNorm2d: 3-260           128\n",
      "|    |    └─Conv2d: 3-261                36,864\n",
      "|    |    └─BatchNorm2d: 3-262           128\n",
      "|    |    └─Dropout: 3-263               --\n",
      "|    |    └─Sequential: 3-264            --\n",
      "|    └─ResidualBlock: 2-45               --\n",
      "|    |    └─Conv2d: 3-265                36,864\n",
      "|    |    └─BatchNorm2d: 3-266           128\n",
      "|    |    └─Conv2d: 3-267                36,864\n",
      "|    |    └─BatchNorm2d: 3-268           128\n",
      "|    |    └─Dropout: 3-269               --\n",
      "|    |    └─Sequential: 3-270            --\n",
      "|    └─ResidualBlock: 2-46               --\n",
      "|    |    └─Conv2d: 3-271                36,864\n",
      "|    |    └─BatchNorm2d: 3-272           128\n",
      "|    |    └─Conv2d: 3-273                36,864\n",
      "|    |    └─BatchNorm2d: 3-274           128\n",
      "|    |    └─Dropout: 3-275               --\n",
      "|    |    └─Sequential: 3-276            --\n",
      "|    └─ResidualBlock: 2-47               --\n",
      "|    |    └─Conv2d: 3-277                36,864\n",
      "|    |    └─BatchNorm2d: 3-278           128\n",
      "|    |    └─Conv2d: 3-279                36,864\n",
      "|    |    └─BatchNorm2d: 3-280           128\n",
      "|    |    └─Dropout: 3-281               --\n",
      "|    |    └─Sequential: 3-282            --\n",
      "|    └─ResidualBlock: 2-48               --\n",
      "|    |    └─Conv2d: 3-283                36,864\n",
      "|    |    └─BatchNorm2d: 3-284           128\n",
      "|    |    └─Conv2d: 3-285                36,864\n",
      "|    |    └─BatchNorm2d: 3-286           128\n",
      "|    |    └─Dropout: 3-287               --\n",
      "|    |    └─Sequential: 3-288            --\n",
      "|    └─ResidualBlock: 2-49               --\n",
      "|    |    └─Conv2d: 3-289                36,864\n",
      "|    |    └─BatchNorm2d: 3-290           128\n",
      "|    |    └─Conv2d: 3-291                36,864\n",
      "|    |    └─BatchNorm2d: 3-292           128\n",
      "|    |    └─Dropout: 3-293               --\n",
      "|    |    └─Sequential: 3-294            --\n",
      "|    └─ResidualBlock: 2-50               --\n",
      "|    |    └─Conv2d: 3-295                36,864\n",
      "|    |    └─BatchNorm2d: 3-296           128\n",
      "|    |    └─Conv2d: 3-297                36,864\n",
      "|    |    └─BatchNorm2d: 3-298           128\n",
      "|    |    └─Dropout: 3-299               --\n",
      "|    |    └─Sequential: 3-300            --\n",
      "|    └─ResidualBlock: 2-51               --\n",
      "|    |    └─Conv2d: 3-301                36,864\n",
      "|    |    └─BatchNorm2d: 3-302           128\n",
      "|    |    └─Conv2d: 3-303                36,864\n",
      "|    |    └─BatchNorm2d: 3-304           128\n",
      "|    |    └─Dropout: 3-305               --\n",
      "|    |    └─Sequential: 3-306            --\n",
      "|    └─ResidualBlock: 2-52               --\n",
      "|    |    └─Conv2d: 3-307                36,864\n",
      "|    |    └─BatchNorm2d: 3-308           128\n",
      "|    |    └─Conv2d: 3-309                36,864\n",
      "|    |    └─BatchNorm2d: 3-310           128\n",
      "|    |    └─Dropout: 3-311               --\n",
      "|    |    └─Sequential: 3-312            --\n",
      "|    └─ResidualBlock: 2-53               --\n",
      "|    |    └─Conv2d: 3-313                36,864\n",
      "|    |    └─BatchNorm2d: 3-314           128\n",
      "|    |    └─Conv2d: 3-315                36,864\n",
      "|    |    └─BatchNorm2d: 3-316           128\n",
      "|    |    └─Dropout: 3-317               --\n",
      "|    |    └─Sequential: 3-318            --\n",
      "|    └─ResidualBlock: 2-54               --\n",
      "|    |    └─Conv2d: 3-319                36,864\n",
      "|    |    └─BatchNorm2d: 3-320           128\n",
      "|    |    └─Conv2d: 3-321                36,864\n",
      "|    |    └─BatchNorm2d: 3-322           128\n",
      "|    |    └─Dropout: 3-323               --\n",
      "|    |    └─Sequential: 3-324            --\n",
      "├─AdaptiveAvgPool2d: 1-6                 --\n",
      "├─Linear: 1-7                            650\n",
      "=================================================================\n",
      "Total params: 1,730,714\n",
      "Trainable params: 1,730,714\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Conv2d: 1-1                            432\n",
       "├─BatchNorm2d: 1-2                       32\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─ResidualBlock: 2-1                --\n",
       "|    |    └─Conv2d: 3-1                  2,304\n",
       "|    |    └─BatchNorm2d: 3-2             32\n",
       "|    |    └─Conv2d: 3-3                  2,304\n",
       "|    |    └─BatchNorm2d: 3-4             32\n",
       "|    |    └─Dropout: 3-5                 --\n",
       "|    |    └─Sequential: 3-6              --\n",
       "|    └─ResidualBlock: 2-2                --\n",
       "|    |    └─Conv2d: 3-7                  2,304\n",
       "|    |    └─BatchNorm2d: 3-8             32\n",
       "|    |    └─Conv2d: 3-9                  2,304\n",
       "|    |    └─BatchNorm2d: 3-10            32\n",
       "|    |    └─Dropout: 3-11                --\n",
       "|    |    └─Sequential: 3-12             --\n",
       "|    └─ResidualBlock: 2-3                --\n",
       "|    |    └─Conv2d: 3-13                 2,304\n",
       "|    |    └─BatchNorm2d: 3-14            32\n",
       "|    |    └─Conv2d: 3-15                 2,304\n",
       "|    |    └─BatchNorm2d: 3-16            32\n",
       "|    |    └─Dropout: 3-17                --\n",
       "|    |    └─Sequential: 3-18             --\n",
       "|    └─ResidualBlock: 2-4                --\n",
       "|    |    └─Conv2d: 3-19                 2,304\n",
       "|    |    └─BatchNorm2d: 3-20            32\n",
       "|    |    └─Conv2d: 3-21                 2,304\n",
       "|    |    └─BatchNorm2d: 3-22            32\n",
       "|    |    └─Dropout: 3-23                --\n",
       "|    |    └─Sequential: 3-24             --\n",
       "|    └─ResidualBlock: 2-5                --\n",
       "|    |    └─Conv2d: 3-25                 2,304\n",
       "|    |    └─BatchNorm2d: 3-26            32\n",
       "|    |    └─Conv2d: 3-27                 2,304\n",
       "|    |    └─BatchNorm2d: 3-28            32\n",
       "|    |    └─Dropout: 3-29                --\n",
       "|    |    └─Sequential: 3-30             --\n",
       "|    └─ResidualBlock: 2-6                --\n",
       "|    |    └─Conv2d: 3-31                 2,304\n",
       "|    |    └─BatchNorm2d: 3-32            32\n",
       "|    |    └─Conv2d: 3-33                 2,304\n",
       "|    |    └─BatchNorm2d: 3-34            32\n",
       "|    |    └─Dropout: 3-35                --\n",
       "|    |    └─Sequential: 3-36             --\n",
       "|    └─ResidualBlock: 2-7                --\n",
       "|    |    └─Conv2d: 3-37                 2,304\n",
       "|    |    └─BatchNorm2d: 3-38            32\n",
       "|    |    └─Conv2d: 3-39                 2,304\n",
       "|    |    └─BatchNorm2d: 3-40            32\n",
       "|    |    └─Dropout: 3-41                --\n",
       "|    |    └─Sequential: 3-42             --\n",
       "|    └─ResidualBlock: 2-8                --\n",
       "|    |    └─Conv2d: 3-43                 2,304\n",
       "|    |    └─BatchNorm2d: 3-44            32\n",
       "|    |    └─Conv2d: 3-45                 2,304\n",
       "|    |    └─BatchNorm2d: 3-46            32\n",
       "|    |    └─Dropout: 3-47                --\n",
       "|    |    └─Sequential: 3-48             --\n",
       "|    └─ResidualBlock: 2-9                --\n",
       "|    |    └─Conv2d: 3-49                 2,304\n",
       "|    |    └─BatchNorm2d: 3-50            32\n",
       "|    |    └─Conv2d: 3-51                 2,304\n",
       "|    |    └─BatchNorm2d: 3-52            32\n",
       "|    |    └─Dropout: 3-53                --\n",
       "|    |    └─Sequential: 3-54             --\n",
       "|    └─ResidualBlock: 2-10               --\n",
       "|    |    └─Conv2d: 3-55                 2,304\n",
       "|    |    └─BatchNorm2d: 3-56            32\n",
       "|    |    └─Conv2d: 3-57                 2,304\n",
       "|    |    └─BatchNorm2d: 3-58            32\n",
       "|    |    └─Dropout: 3-59                --\n",
       "|    |    └─Sequential: 3-60             --\n",
       "|    └─ResidualBlock: 2-11               --\n",
       "|    |    └─Conv2d: 3-61                 2,304\n",
       "|    |    └─BatchNorm2d: 3-62            32\n",
       "|    |    └─Conv2d: 3-63                 2,304\n",
       "|    |    └─BatchNorm2d: 3-64            32\n",
       "|    |    └─Dropout: 3-65                --\n",
       "|    |    └─Sequential: 3-66             --\n",
       "|    └─ResidualBlock: 2-12               --\n",
       "|    |    └─Conv2d: 3-67                 2,304\n",
       "|    |    └─BatchNorm2d: 3-68            32\n",
       "|    |    └─Conv2d: 3-69                 2,304\n",
       "|    |    └─BatchNorm2d: 3-70            32\n",
       "|    |    └─Dropout: 3-71                --\n",
       "|    |    └─Sequential: 3-72             --\n",
       "|    └─ResidualBlock: 2-13               --\n",
       "|    |    └─Conv2d: 3-73                 2,304\n",
       "|    |    └─BatchNorm2d: 3-74            32\n",
       "|    |    └─Conv2d: 3-75                 2,304\n",
       "|    |    └─BatchNorm2d: 3-76            32\n",
       "|    |    └─Dropout: 3-77                --\n",
       "|    |    └─Sequential: 3-78             --\n",
       "|    └─ResidualBlock: 2-14               --\n",
       "|    |    └─Conv2d: 3-79                 2,304\n",
       "|    |    └─BatchNorm2d: 3-80            32\n",
       "|    |    └─Conv2d: 3-81                 2,304\n",
       "|    |    └─BatchNorm2d: 3-82            32\n",
       "|    |    └─Dropout: 3-83                --\n",
       "|    |    └─Sequential: 3-84             --\n",
       "|    └─ResidualBlock: 2-15               --\n",
       "|    |    └─Conv2d: 3-85                 2,304\n",
       "|    |    └─BatchNorm2d: 3-86            32\n",
       "|    |    └─Conv2d: 3-87                 2,304\n",
       "|    |    └─BatchNorm2d: 3-88            32\n",
       "|    |    └─Dropout: 3-89                --\n",
       "|    |    └─Sequential: 3-90             --\n",
       "|    └─ResidualBlock: 2-16               --\n",
       "|    |    └─Conv2d: 3-91                 2,304\n",
       "|    |    └─BatchNorm2d: 3-92            32\n",
       "|    |    └─Conv2d: 3-93                 2,304\n",
       "|    |    └─BatchNorm2d: 3-94            32\n",
       "|    |    └─Dropout: 3-95                --\n",
       "|    |    └─Sequential: 3-96             --\n",
       "|    └─ResidualBlock: 2-17               --\n",
       "|    |    └─Conv2d: 3-97                 2,304\n",
       "|    |    └─BatchNorm2d: 3-98            32\n",
       "|    |    └─Conv2d: 3-99                 2,304\n",
       "|    |    └─BatchNorm2d: 3-100           32\n",
       "|    |    └─Dropout: 3-101               --\n",
       "|    |    └─Sequential: 3-102            --\n",
       "|    └─ResidualBlock: 2-18               --\n",
       "|    |    └─Conv2d: 3-103                2,304\n",
       "|    |    └─BatchNorm2d: 3-104           32\n",
       "|    |    └─Conv2d: 3-105                2,304\n",
       "|    |    └─BatchNorm2d: 3-106           32\n",
       "|    |    └─Dropout: 3-107               --\n",
       "|    |    └─Sequential: 3-108            --\n",
       "├─Sequential: 1-4                        --\n",
       "|    └─ResidualBlock: 2-19               --\n",
       "|    |    └─Conv2d: 3-109                4,608\n",
       "|    |    └─BatchNorm2d: 3-110           64\n",
       "|    |    └─Conv2d: 3-111                9,216\n",
       "|    |    └─BatchNorm2d: 3-112           64\n",
       "|    |    └─Dropout: 3-113               --\n",
       "|    |    └─Sequential: 3-114            576\n",
       "|    └─ResidualBlock: 2-20               --\n",
       "|    |    └─Conv2d: 3-115                9,216\n",
       "|    |    └─BatchNorm2d: 3-116           64\n",
       "|    |    └─Conv2d: 3-117                9,216\n",
       "|    |    └─BatchNorm2d: 3-118           64\n",
       "|    |    └─Dropout: 3-119               --\n",
       "|    |    └─Sequential: 3-120            --\n",
       "|    └─ResidualBlock: 2-21               --\n",
       "|    |    └─Conv2d: 3-121                9,216\n",
       "|    |    └─BatchNorm2d: 3-122           64\n",
       "|    |    └─Conv2d: 3-123                9,216\n",
       "|    |    └─BatchNorm2d: 3-124           64\n",
       "|    |    └─Dropout: 3-125               --\n",
       "|    |    └─Sequential: 3-126            --\n",
       "|    └─ResidualBlock: 2-22               --\n",
       "|    |    └─Conv2d: 3-127                9,216\n",
       "|    |    └─BatchNorm2d: 3-128           64\n",
       "|    |    └─Conv2d: 3-129                9,216\n",
       "|    |    └─BatchNorm2d: 3-130           64\n",
       "|    |    └─Dropout: 3-131               --\n",
       "|    |    └─Sequential: 3-132            --\n",
       "|    └─ResidualBlock: 2-23               --\n",
       "|    |    └─Conv2d: 3-133                9,216\n",
       "|    |    └─BatchNorm2d: 3-134           64\n",
       "|    |    └─Conv2d: 3-135                9,216\n",
       "|    |    └─BatchNorm2d: 3-136           64\n",
       "|    |    └─Dropout: 3-137               --\n",
       "|    |    └─Sequential: 3-138            --\n",
       "|    └─ResidualBlock: 2-24               --\n",
       "|    |    └─Conv2d: 3-139                9,216\n",
       "|    |    └─BatchNorm2d: 3-140           64\n",
       "|    |    └─Conv2d: 3-141                9,216\n",
       "|    |    └─BatchNorm2d: 3-142           64\n",
       "|    |    └─Dropout: 3-143               --\n",
       "|    |    └─Sequential: 3-144            --\n",
       "|    └─ResidualBlock: 2-25               --\n",
       "|    |    └─Conv2d: 3-145                9,216\n",
       "|    |    └─BatchNorm2d: 3-146           64\n",
       "|    |    └─Conv2d: 3-147                9,216\n",
       "|    |    └─BatchNorm2d: 3-148           64\n",
       "|    |    └─Dropout: 3-149               --\n",
       "|    |    └─Sequential: 3-150            --\n",
       "|    └─ResidualBlock: 2-26               --\n",
       "|    |    └─Conv2d: 3-151                9,216\n",
       "|    |    └─BatchNorm2d: 3-152           64\n",
       "|    |    └─Conv2d: 3-153                9,216\n",
       "|    |    └─BatchNorm2d: 3-154           64\n",
       "|    |    └─Dropout: 3-155               --\n",
       "|    |    └─Sequential: 3-156            --\n",
       "|    └─ResidualBlock: 2-27               --\n",
       "|    |    └─Conv2d: 3-157                9,216\n",
       "|    |    └─BatchNorm2d: 3-158           64\n",
       "|    |    └─Conv2d: 3-159                9,216\n",
       "|    |    └─BatchNorm2d: 3-160           64\n",
       "|    |    └─Dropout: 3-161               --\n",
       "|    |    └─Sequential: 3-162            --\n",
       "|    └─ResidualBlock: 2-28               --\n",
       "|    |    └─Conv2d: 3-163                9,216\n",
       "|    |    └─BatchNorm2d: 3-164           64\n",
       "|    |    └─Conv2d: 3-165                9,216\n",
       "|    |    └─BatchNorm2d: 3-166           64\n",
       "|    |    └─Dropout: 3-167               --\n",
       "|    |    └─Sequential: 3-168            --\n",
       "|    └─ResidualBlock: 2-29               --\n",
       "|    |    └─Conv2d: 3-169                9,216\n",
       "|    |    └─BatchNorm2d: 3-170           64\n",
       "|    |    └─Conv2d: 3-171                9,216\n",
       "|    |    └─BatchNorm2d: 3-172           64\n",
       "|    |    └─Dropout: 3-173               --\n",
       "|    |    └─Sequential: 3-174            --\n",
       "|    └─ResidualBlock: 2-30               --\n",
       "|    |    └─Conv2d: 3-175                9,216\n",
       "|    |    └─BatchNorm2d: 3-176           64\n",
       "|    |    └─Conv2d: 3-177                9,216\n",
       "|    |    └─BatchNorm2d: 3-178           64\n",
       "|    |    └─Dropout: 3-179               --\n",
       "|    |    └─Sequential: 3-180            --\n",
       "|    └─ResidualBlock: 2-31               --\n",
       "|    |    └─Conv2d: 3-181                9,216\n",
       "|    |    └─BatchNorm2d: 3-182           64\n",
       "|    |    └─Conv2d: 3-183                9,216\n",
       "|    |    └─BatchNorm2d: 3-184           64\n",
       "|    |    └─Dropout: 3-185               --\n",
       "|    |    └─Sequential: 3-186            --\n",
       "|    └─ResidualBlock: 2-32               --\n",
       "|    |    └─Conv2d: 3-187                9,216\n",
       "|    |    └─BatchNorm2d: 3-188           64\n",
       "|    |    └─Conv2d: 3-189                9,216\n",
       "|    |    └─BatchNorm2d: 3-190           64\n",
       "|    |    └─Dropout: 3-191               --\n",
       "|    |    └─Sequential: 3-192            --\n",
       "|    └─ResidualBlock: 2-33               --\n",
       "|    |    └─Conv2d: 3-193                9,216\n",
       "|    |    └─BatchNorm2d: 3-194           64\n",
       "|    |    └─Conv2d: 3-195                9,216\n",
       "|    |    └─BatchNorm2d: 3-196           64\n",
       "|    |    └─Dropout: 3-197               --\n",
       "|    |    └─Sequential: 3-198            --\n",
       "|    └─ResidualBlock: 2-34               --\n",
       "|    |    └─Conv2d: 3-199                9,216\n",
       "|    |    └─BatchNorm2d: 3-200           64\n",
       "|    |    └─Conv2d: 3-201                9,216\n",
       "|    |    └─BatchNorm2d: 3-202           64\n",
       "|    |    └─Dropout: 3-203               --\n",
       "|    |    └─Sequential: 3-204            --\n",
       "|    └─ResidualBlock: 2-35               --\n",
       "|    |    └─Conv2d: 3-205                9,216\n",
       "|    |    └─BatchNorm2d: 3-206           64\n",
       "|    |    └─Conv2d: 3-207                9,216\n",
       "|    |    └─BatchNorm2d: 3-208           64\n",
       "|    |    └─Dropout: 3-209               --\n",
       "|    |    └─Sequential: 3-210            --\n",
       "|    └─ResidualBlock: 2-36               --\n",
       "|    |    └─Conv2d: 3-211                9,216\n",
       "|    |    └─BatchNorm2d: 3-212           64\n",
       "|    |    └─Conv2d: 3-213                9,216\n",
       "|    |    └─BatchNorm2d: 3-214           64\n",
       "|    |    └─Dropout: 3-215               --\n",
       "|    |    └─Sequential: 3-216            --\n",
       "├─Sequential: 1-5                        --\n",
       "|    └─ResidualBlock: 2-37               --\n",
       "|    |    └─Conv2d: 3-217                18,432\n",
       "|    |    └─BatchNorm2d: 3-218           128\n",
       "|    |    └─Conv2d: 3-219                36,864\n",
       "|    |    └─BatchNorm2d: 3-220           128\n",
       "|    |    └─Dropout: 3-221               --\n",
       "|    |    └─Sequential: 3-222            2,176\n",
       "|    └─ResidualBlock: 2-38               --\n",
       "|    |    └─Conv2d: 3-223                36,864\n",
       "|    |    └─BatchNorm2d: 3-224           128\n",
       "|    |    └─Conv2d: 3-225                36,864\n",
       "|    |    └─BatchNorm2d: 3-226           128\n",
       "|    |    └─Dropout: 3-227               --\n",
       "|    |    └─Sequential: 3-228            --\n",
       "|    └─ResidualBlock: 2-39               --\n",
       "|    |    └─Conv2d: 3-229                36,864\n",
       "|    |    └─BatchNorm2d: 3-230           128\n",
       "|    |    └─Conv2d: 3-231                36,864\n",
       "|    |    └─BatchNorm2d: 3-232           128\n",
       "|    |    └─Dropout: 3-233               --\n",
       "|    |    └─Sequential: 3-234            --\n",
       "|    └─ResidualBlock: 2-40               --\n",
       "|    |    └─Conv2d: 3-235                36,864\n",
       "|    |    └─BatchNorm2d: 3-236           128\n",
       "|    |    └─Conv2d: 3-237                36,864\n",
       "|    |    └─BatchNorm2d: 3-238           128\n",
       "|    |    └─Dropout: 3-239               --\n",
       "|    |    └─Sequential: 3-240            --\n",
       "|    └─ResidualBlock: 2-41               --\n",
       "|    |    └─Conv2d: 3-241                36,864\n",
       "|    |    └─BatchNorm2d: 3-242           128\n",
       "|    |    └─Conv2d: 3-243                36,864\n",
       "|    |    └─BatchNorm2d: 3-244           128\n",
       "|    |    └─Dropout: 3-245               --\n",
       "|    |    └─Sequential: 3-246            --\n",
       "|    └─ResidualBlock: 2-42               --\n",
       "|    |    └─Conv2d: 3-247                36,864\n",
       "|    |    └─BatchNorm2d: 3-248           128\n",
       "|    |    └─Conv2d: 3-249                36,864\n",
       "|    |    └─BatchNorm2d: 3-250           128\n",
       "|    |    └─Dropout: 3-251               --\n",
       "|    |    └─Sequential: 3-252            --\n",
       "|    └─ResidualBlock: 2-43               --\n",
       "|    |    └─Conv2d: 3-253                36,864\n",
       "|    |    └─BatchNorm2d: 3-254           128\n",
       "|    |    └─Conv2d: 3-255                36,864\n",
       "|    |    └─BatchNorm2d: 3-256           128\n",
       "|    |    └─Dropout: 3-257               --\n",
       "|    |    └─Sequential: 3-258            --\n",
       "|    └─ResidualBlock: 2-44               --\n",
       "|    |    └─Conv2d: 3-259                36,864\n",
       "|    |    └─BatchNorm2d: 3-260           128\n",
       "|    |    └─Conv2d: 3-261                36,864\n",
       "|    |    └─BatchNorm2d: 3-262           128\n",
       "|    |    └─Dropout: 3-263               --\n",
       "|    |    └─Sequential: 3-264            --\n",
       "|    └─ResidualBlock: 2-45               --\n",
       "|    |    └─Conv2d: 3-265                36,864\n",
       "|    |    └─BatchNorm2d: 3-266           128\n",
       "|    |    └─Conv2d: 3-267                36,864\n",
       "|    |    └─BatchNorm2d: 3-268           128\n",
       "|    |    └─Dropout: 3-269               --\n",
       "|    |    └─Sequential: 3-270            --\n",
       "|    └─ResidualBlock: 2-46               --\n",
       "|    |    └─Conv2d: 3-271                36,864\n",
       "|    |    └─BatchNorm2d: 3-272           128\n",
       "|    |    └─Conv2d: 3-273                36,864\n",
       "|    |    └─BatchNorm2d: 3-274           128\n",
       "|    |    └─Dropout: 3-275               --\n",
       "|    |    └─Sequential: 3-276            --\n",
       "|    └─ResidualBlock: 2-47               --\n",
       "|    |    └─Conv2d: 3-277                36,864\n",
       "|    |    └─BatchNorm2d: 3-278           128\n",
       "|    |    └─Conv2d: 3-279                36,864\n",
       "|    |    └─BatchNorm2d: 3-280           128\n",
       "|    |    └─Dropout: 3-281               --\n",
       "|    |    └─Sequential: 3-282            --\n",
       "|    └─ResidualBlock: 2-48               --\n",
       "|    |    └─Conv2d: 3-283                36,864\n",
       "|    |    └─BatchNorm2d: 3-284           128\n",
       "|    |    └─Conv2d: 3-285                36,864\n",
       "|    |    └─BatchNorm2d: 3-286           128\n",
       "|    |    └─Dropout: 3-287               --\n",
       "|    |    └─Sequential: 3-288            --\n",
       "|    └─ResidualBlock: 2-49               --\n",
       "|    |    └─Conv2d: 3-289                36,864\n",
       "|    |    └─BatchNorm2d: 3-290           128\n",
       "|    |    └─Conv2d: 3-291                36,864\n",
       "|    |    └─BatchNorm2d: 3-292           128\n",
       "|    |    └─Dropout: 3-293               --\n",
       "|    |    └─Sequential: 3-294            --\n",
       "|    └─ResidualBlock: 2-50               --\n",
       "|    |    └─Conv2d: 3-295                36,864\n",
       "|    |    └─BatchNorm2d: 3-296           128\n",
       "|    |    └─Conv2d: 3-297                36,864\n",
       "|    |    └─BatchNorm2d: 3-298           128\n",
       "|    |    └─Dropout: 3-299               --\n",
       "|    |    └─Sequential: 3-300            --\n",
       "|    └─ResidualBlock: 2-51               --\n",
       "|    |    └─Conv2d: 3-301                36,864\n",
       "|    |    └─BatchNorm2d: 3-302           128\n",
       "|    |    └─Conv2d: 3-303                36,864\n",
       "|    |    └─BatchNorm2d: 3-304           128\n",
       "|    |    └─Dropout: 3-305               --\n",
       "|    |    └─Sequential: 3-306            --\n",
       "|    └─ResidualBlock: 2-52               --\n",
       "|    |    └─Conv2d: 3-307                36,864\n",
       "|    |    └─BatchNorm2d: 3-308           128\n",
       "|    |    └─Conv2d: 3-309                36,864\n",
       "|    |    └─BatchNorm2d: 3-310           128\n",
       "|    |    └─Dropout: 3-311               --\n",
       "|    |    └─Sequential: 3-312            --\n",
       "|    └─ResidualBlock: 2-53               --\n",
       "|    |    └─Conv2d: 3-313                36,864\n",
       "|    |    └─BatchNorm2d: 3-314           128\n",
       "|    |    └─Conv2d: 3-315                36,864\n",
       "|    |    └─BatchNorm2d: 3-316           128\n",
       "|    |    └─Dropout: 3-317               --\n",
       "|    |    └─Sequential: 3-318            --\n",
       "|    └─ResidualBlock: 2-54               --\n",
       "|    |    └─Conv2d: 3-319                36,864\n",
       "|    |    └─BatchNorm2d: 3-320           128\n",
       "|    |    └─Conv2d: 3-321                36,864\n",
       "|    |    └─BatchNorm2d: 3-322           128\n",
       "|    |    └─Dropout: 3-323               --\n",
       "|    |    └─Sequential: 3-324            --\n",
       "├─AdaptiveAvgPool2d: 1-6                 --\n",
       "├─Linear: 1-7                            650\n",
       "=================================================================\n",
       "Total params: 1,730,714\n",
       "Trainable params: 1,730,714\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(ResidualBlock, [18, 18, 18], dropout_rate=0.5).to(device)\n",
    "\n",
    "total_layers = sum([1 for _ in model.modules() \n",
    "    if isinstance(_, nn.Conv2d) or isinstance(_, nn.Linear)]) - 2 # subtract input and output layers\n",
    "    \n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total number of layers: {total_layers}\")\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.0001)\n",
    "\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 56s\n",
      "\tTrain Loss: 2.417 | Train Acc: 12.10% | LR: 0.099994\n",
      "\t Val. Loss: 2.195 |  Val. Acc: 17.44%\n",
      "Epoch: 02 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 2.032 | Train Acc: 24.23% | LR: 0.099975\n",
      "\t Val. Loss: 2.030 |  Val. Acc: 28.01%\n",
      "Epoch: 03 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.820 | Train Acc: 31.25% | LR: 0.099944\n",
      "\t Val. Loss: 1.740 |  Val. Acc: 36.08%\n",
      "Epoch: 04 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.670 | Train Acc: 37.22% | LR: 0.099901\n",
      "\t Val. Loss: 1.637 |  Val. Acc: 39.34%\n",
      "Epoch: 05 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.553 | Train Acc: 42.62% | LR: 0.099846\n",
      "\t Val. Loss: 1.510 |  Val. Acc: 45.25%\n",
      "Epoch: 06 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.442 | Train Acc: 46.66% | LR: 0.099778\n",
      "\t Val. Loss: 1.545 |  Val. Acc: 45.83%\n",
      "Epoch: 07 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.344 | Train Acc: 51.29% | LR: 0.099698\n",
      "\t Val. Loss: 1.223 |  Val. Acc: 55.97%\n",
      "Epoch: 08 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.245 | Train Acc: 55.11% | LR: 0.099606\n",
      "\t Val. Loss: 1.258 |  Val. Acc: 55.46%\n",
      "Epoch: 09 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.171 | Train Acc: 58.19% | LR: 0.099501\n",
      "\t Val. Loss: 1.146 |  Val. Acc: 61.04%\n",
      "Epoch: 10 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 1.083 | Train Acc: 61.51% | LR: 0.099384\n",
      "\t Val. Loss: 1.006 |  Val. Acc: 64.18%\n",
      "Epoch: 11 | Epoch Time: 0m 54s\n",
      "\tTrain Loss: 1.022 | Train Acc: 63.62% | LR: 0.099255\n",
      "\t Val. Loss: 0.959 |  Val. Acc: 66.32%\n",
      "Epoch: 12 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.969 | Train Acc: 65.70% | LR: 0.099114\n",
      "\t Val. Loss: 0.964 |  Val. Acc: 67.17%\n",
      "Epoch: 13 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.927 | Train Acc: 67.14% | LR: 0.098961\n",
      "\t Val. Loss: 0.880 |  Val. Acc: 69.68%\n",
      "Epoch: 14 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.881 | Train Acc: 69.12% | LR: 0.098796\n",
      "\t Val. Loss: 0.852 |  Val. Acc: 71.18%\n",
      "Epoch: 15 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.842 | Train Acc: 70.38% | LR: 0.098618\n",
      "\t Val. Loss: 0.810 |  Val. Acc: 73.02%\n",
      "Epoch: 16 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.799 | Train Acc: 72.05% | LR: 0.098429\n",
      "\t Val. Loss: 0.780 |  Val. Acc: 73.95%\n",
      "Epoch: 17 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.769 | Train Acc: 73.03% | LR: 0.098228\n",
      "\t Val. Loss: 0.776 |  Val. Acc: 74.43%\n",
      "Epoch: 18 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.762 | Train Acc: 73.66% | LR: 0.098015\n",
      "\t Val. Loss: 0.785 |  Val. Acc: 74.64%\n",
      "Epoch: 19 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.713 | Train Acc: 75.10% | LR: 0.097790\n",
      "\t Val. Loss: 0.691 |  Val. Acc: 77.45%\n",
      "Epoch: 20 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.696 | Train Acc: 75.86% | LR: 0.097553\n",
      "\t Val. Loss: 0.605 |  Val. Acc: 79.92%\n",
      "Epoch: 21 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.671 | Train Acc: 76.73% | LR: 0.097304\n",
      "\t Val. Loss: 0.627 |  Val. Acc: 79.37%\n",
      "Epoch: 22 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.649 | Train Acc: 77.37% | LR: 0.097044\n",
      "\t Val. Loss: 0.575 |  Val. Acc: 81.45%\n",
      "Epoch: 23 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.633 | Train Acc: 78.06% | LR: 0.096772\n",
      "\t Val. Loss: 0.598 |  Val. Acc: 80.20%\n",
      "Epoch: 24 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.620 | Train Acc: 78.37% | LR: 0.096489\n",
      "\t Val. Loss: 0.535 |  Val. Acc: 81.61%\n",
      "Epoch: 25 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.607 | Train Acc: 78.74% | LR: 0.096194\n",
      "\t Val. Loss: 0.519 |  Val. Acc: 82.73%\n",
      "Epoch: 26 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.584 | Train Acc: 79.65% | LR: 0.095888\n",
      "\t Val. Loss: 0.524 |  Val. Acc: 83.17%\n",
      "Epoch: 27 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.572 | Train Acc: 80.02% | LR: 0.095570\n",
      "\t Val. Loss: 0.530 |  Val. Acc: 82.97%\n",
      "Epoch: 28 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.566 | Train Acc: 80.26% | LR: 0.095241\n",
      "\t Val. Loss: 0.515 |  Val. Acc: 83.17%\n",
      "Epoch: 29 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.551 | Train Acc: 80.83% | LR: 0.094901\n",
      "\t Val. Loss: 0.509 |  Val. Acc: 83.45%\n",
      "Epoch: 30 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.543 | Train Acc: 81.02% | LR: 0.094550\n",
      "\t Val. Loss: 0.501 |  Val. Acc: 83.62%\n",
      "Epoch: 31 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.531 | Train Acc: 81.61% | LR: 0.094188\n",
      "\t Val. Loss: 0.485 |  Val. Acc: 84.24%\n",
      "Epoch: 32 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.518 | Train Acc: 81.85% | LR: 0.093815\n",
      "\t Val. Loss: 0.495 |  Val. Acc: 84.16%\n",
      "Epoch: 33 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.514 | Train Acc: 82.03% | LR: 0.093432\n",
      "\t Val. Loss: 0.465 |  Val. Acc: 85.50%\n",
      "Epoch: 34 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.503 | Train Acc: 82.25% | LR: 0.093037\n",
      "\t Val. Loss: 0.519 |  Val. Acc: 83.27%\n",
      "Epoch: 35 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.499 | Train Acc: 82.90% | LR: 0.092632\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 84.99%\n",
      "Epoch: 36 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.486 | Train Acc: 83.10% | LR: 0.092216\n",
      "\t Val. Loss: 0.468 |  Val. Acc: 85.28%\n",
      "Epoch: 37 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.484 | Train Acc: 83.02% | LR: 0.091790\n",
      "\t Val. Loss: 0.446 |  Val. Acc: 85.19%\n",
      "Epoch: 38 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.472 | Train Acc: 83.47% | LR: 0.091354\n",
      "\t Val. Loss: 0.454 |  Val. Acc: 85.50%\n",
      "Epoch: 39 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.467 | Train Acc: 83.73% | LR: 0.090907\n",
      "\t Val. Loss: 0.452 |  Val. Acc: 85.30%\n",
      "Epoch: 40 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.454 | Train Acc: 84.23% | LR: 0.090451\n",
      "\t Val. Loss: 0.426 |  Val. Acc: 86.19%\n",
      "Epoch: 41 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.452 | Train Acc: 84.08% | LR: 0.089984\n",
      "\t Val. Loss: 0.445 |  Val. Acc: 85.86%\n",
      "Epoch: 42 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.452 | Train Acc: 84.35% | LR: 0.089508\n",
      "\t Val. Loss: 0.438 |  Val. Acc: 86.25%\n",
      "Epoch: 43 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.443 | Train Acc: 84.50% | LR: 0.089022\n",
      "\t Val. Loss: 0.430 |  Val. Acc: 85.94%\n",
      "Epoch: 44 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.439 | Train Acc: 84.75% | LR: 0.088526\n",
      "\t Val. Loss: 0.412 |  Val. Acc: 87.10%\n",
      "Epoch: 45 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.429 | Train Acc: 85.06% | LR: 0.088020\n",
      "\t Val. Loss: 0.453 |  Val. Acc: 85.72%\n",
      "Epoch: 46 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.428 | Train Acc: 85.12% | LR: 0.087506\n",
      "\t Val. Loss: 0.468 |  Val. Acc: 85.48%\n",
      "Epoch: 47 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.419 | Train Acc: 85.28% | LR: 0.086982\n",
      "\t Val. Loss: 0.441 |  Val. Acc: 86.12%\n",
      "Epoch: 48 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.416 | Train Acc: 85.48% | LR: 0.086448\n",
      "\t Val. Loss: 0.423 |  Val. Acc: 86.49%\n",
      "Epoch: 49 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.406 | Train Acc: 85.80% | LR: 0.085906\n",
      "\t Val. Loss: 0.407 |  Val. Acc: 86.83%\n",
      "Epoch: 50 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.406 | Train Acc: 85.87% | LR: 0.085355\n",
      "\t Val. Loss: 0.434 |  Val. Acc: 86.43%\n",
      "Epoch: 51 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.397 | Train Acc: 86.10% | LR: 0.084796\n",
      "\t Val. Loss: 0.436 |  Val. Acc: 85.96%\n",
      "Epoch: 52 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.400 | Train Acc: 86.06% | LR: 0.084227\n",
      "\t Val. Loss: 0.442 |  Val. Acc: 86.33%\n",
      "Epoch: 53 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.392 | Train Acc: 86.31% | LR: 0.083651\n",
      "\t Val. Loss: 0.392 |  Val. Acc: 87.60%\n",
      "Epoch: 54 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.382 | Train Acc: 86.66% | LR: 0.083066\n",
      "\t Val. Loss: 0.401 |  Val. Acc: 87.24%\n",
      "Epoch: 55 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.381 | Train Acc: 86.70% | LR: 0.082472\n",
      "\t Val. Loss: 0.372 |  Val. Acc: 88.01%\n",
      "Epoch: 56 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.377 | Train Acc: 86.71% | LR: 0.081871\n",
      "\t Val. Loss: 0.407 |  Val. Acc: 87.80%\n",
      "Epoch: 57 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.372 | Train Acc: 86.85% | LR: 0.081262\n",
      "\t Val. Loss: 0.406 |  Val. Acc: 87.38%\n",
      "Epoch: 58 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.368 | Train Acc: 87.11% | LR: 0.080645\n",
      "\t Val. Loss: 0.448 |  Val. Acc: 86.65%\n",
      "Epoch: 59 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.365 | Train Acc: 87.20% | LR: 0.080021\n",
      "\t Val. Loss: 0.432 |  Val. Acc: 87.03%\n",
      "Epoch: 60 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.363 | Train Acc: 87.37% | LR: 0.079389\n",
      "\t Val. Loss: 0.450 |  Val. Acc: 85.90%\n",
      "Epoch: 61 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.360 | Train Acc: 87.47% | LR: 0.078750\n",
      "\t Val. Loss: 0.378 |  Val. Acc: 88.53%\n",
      "Epoch: 62 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.356 | Train Acc: 87.51% | LR: 0.078104\n",
      "\t Val. Loss: 0.387 |  Val. Acc: 88.15%\n",
      "Epoch: 63 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.350 | Train Acc: 87.62% | LR: 0.077451\n",
      "\t Val. Loss: 0.387 |  Val. Acc: 87.60%\n",
      "Epoch: 64 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.348 | Train Acc: 87.73% | LR: 0.076791\n",
      "\t Val. Loss: 0.370 |  Val. Acc: 88.47%\n",
      "Epoch: 65 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.343 | Train Acc: 87.93% | LR: 0.076125\n",
      "\t Val. Loss: 0.393 |  Val. Acc: 87.88%\n",
      "Epoch: 66 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.341 | Train Acc: 87.99% | LR: 0.075452\n",
      "\t Val. Loss: 0.383 |  Val. Acc: 87.86%\n",
      "Epoch: 67 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.337 | Train Acc: 88.21% | LR: 0.074773\n",
      "\t Val. Loss: 0.368 |  Val. Acc: 88.47%\n",
      "Epoch: 68 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.337 | Train Acc: 88.32% | LR: 0.074088\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 88.69%\n",
      "Epoch: 69 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.328 | Train Acc: 88.44% | LR: 0.073396\n",
      "\t Val. Loss: 0.388 |  Val. Acc: 87.97%\n",
      "Epoch: 70 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.330 | Train Acc: 88.47% | LR: 0.072700\n",
      "\t Val. Loss: 0.446 |  Val. Acc: 87.42%\n",
      "Epoch: 71 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.326 | Train Acc: 88.60% | LR: 0.071997\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 88.92%\n",
      "Epoch: 72 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.320 | Train Acc: 88.86% | LR: 0.071289\n",
      "\t Val. Loss: 0.388 |  Val. Acc: 88.07%\n",
      "Epoch: 73 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.317 | Train Acc: 88.75% | LR: 0.070576\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 88.65%\n",
      "Epoch: 74 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.313 | Train Acc: 89.15% | LR: 0.069857\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 88.98%\n",
      "Epoch: 75 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.317 | Train Acc: 88.69% | LR: 0.069134\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 88.71%\n",
      "Epoch: 76 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.313 | Train Acc: 88.94% | LR: 0.068406\n",
      "\t Val. Loss: 0.382 |  Val. Acc: 88.86%\n",
      "Epoch: 77 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.308 | Train Acc: 89.12% | LR: 0.067674\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 89.22%\n",
      "Epoch: 78 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.305 | Train Acc: 89.04% | LR: 0.066937\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 88.77%\n",
      "Epoch: 79 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.303 | Train Acc: 89.28% | LR: 0.066196\n",
      "\t Val. Loss: 0.399 |  Val. Acc: 87.99%\n",
      "Epoch: 80 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.301 | Train Acc: 89.35% | LR: 0.065451\n",
      "\t Val. Loss: 0.338 |  Val. Acc: 89.22%\n",
      "Epoch: 81 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.296 | Train Acc: 89.55% | LR: 0.064702\n",
      "\t Val. Loss: 0.379 |  Val. Acc: 88.47%\n",
      "Epoch: 82 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.296 | Train Acc: 89.62% | LR: 0.063950\n",
      "\t Val. Loss: 0.366 |  Val. Acc: 88.90%\n",
      "Epoch: 83 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.293 | Train Acc: 89.70% | LR: 0.063194\n",
      "\t Val. Loss: 0.374 |  Val. Acc: 88.81%\n",
      "Epoch: 84 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.287 | Train Acc: 89.77% | LR: 0.062434\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 89.52%\n",
      "Epoch: 85 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.285 | Train Acc: 89.77% | LR: 0.061672\n",
      "\t Val. Loss: 0.367 |  Val. Acc: 88.86%\n",
      "Epoch: 86 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.278 | Train Acc: 90.12% | LR: 0.060907\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 89.54%\n",
      "Epoch: 87 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.279 | Train Acc: 90.09% | LR: 0.060139\n",
      "\t Val. Loss: 0.378 |  Val. Acc: 88.77%\n",
      "Epoch: 88 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.278 | Train Acc: 90.16% | LR: 0.059369\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 89.54%\n",
      "Epoch: 89 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.277 | Train Acc: 90.08% | LR: 0.058596\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 89.34%\n",
      "Epoch: 90 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.273 | Train Acc: 90.47% | LR: 0.057822\n",
      "\t Val. Loss: 0.373 |  Val. Acc: 88.94%\n",
      "Epoch: 91 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.270 | Train Acc: 90.41% | LR: 0.057045\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 89.46%\n",
      "Epoch: 92 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.273 | Train Acc: 90.39% | LR: 0.056267\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 89.30%\n",
      "Epoch: 93 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.265 | Train Acc: 90.53% | LR: 0.055487\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 89.72%\n",
      "Epoch: 94 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.263 | Train Acc: 90.61% | LR: 0.054705\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 89.36%\n",
      "Epoch: 95 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.262 | Train Acc: 90.68% | LR: 0.053923\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 89.24%\n",
      "Epoch: 96 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.255 | Train Acc: 91.00% | LR: 0.053140\n",
      "\t Val. Loss: 0.338 |  Val. Acc: 89.91%\n",
      "Epoch: 97 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.259 | Train Acc: 90.82% | LR: 0.052355\n",
      "\t Val. Loss: 0.336 |  Val. Acc: 90.07%\n",
      "Epoch: 98 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.254 | Train Acc: 90.86% | LR: 0.051571\n",
      "\t Val. Loss: 0.366 |  Val. Acc: 89.83%\n",
      "Epoch: 99 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.253 | Train Acc: 90.97% | LR: 0.050785\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 89.89%\n",
      "Epoch: 100 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.250 | Train Acc: 91.17% | LR: 0.050000\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 89.62%\n",
      "Epoch: 101 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.249 | Train Acc: 91.29% | LR: 0.049215\n",
      "\t Val. Loss: 0.329 |  Val. Acc: 90.15%\n",
      "Epoch: 102 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.244 | Train Acc: 91.27% | LR: 0.048429\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 89.83%\n",
      "Epoch: 103 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.244 | Train Acc: 91.37% | LR: 0.047645\n",
      "\t Val. Loss: 0.319 |  Val. Acc: 90.72%\n",
      "Epoch: 104 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.246 | Train Acc: 91.33% | LR: 0.046860\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 90.03%\n",
      "Epoch: 105 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.239 | Train Acc: 91.61% | LR: 0.046077\n",
      "\t Val. Loss: 0.326 |  Val. Acc: 90.53%\n",
      "Epoch: 106 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.241 | Train Acc: 91.44% | LR: 0.045295\n",
      "\t Val. Loss: 0.339 |  Val. Acc: 90.35%\n",
      "Epoch: 107 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.232 | Train Acc: 91.72% | LR: 0.044513\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 90.05%\n",
      "Epoch: 108 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.234 | Train Acc: 91.75% | LR: 0.043733\n",
      "\t Val. Loss: 0.338 |  Val. Acc: 90.49%\n",
      "Epoch: 109 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.231 | Train Acc: 91.69% | LR: 0.042955\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 89.87%\n",
      "Epoch: 110 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.231 | Train Acc: 91.76% | LR: 0.042178\n",
      "\t Val. Loss: 0.325 |  Val. Acc: 90.70%\n",
      "Epoch: 111 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.225 | Train Acc: 91.98% | LR: 0.041404\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 90.64%\n",
      "Epoch: 112 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.230 | Train Acc: 91.98% | LR: 0.040631\n",
      "\t Val. Loss: 0.341 |  Val. Acc: 90.19%\n",
      "Epoch: 113 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.229 | Train Acc: 91.94% | LR: 0.039861\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.49%\n",
      "Epoch: 114 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.224 | Train Acc: 92.00% | LR: 0.039093\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 90.82%\n",
      "Epoch: 115 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.221 | Train Acc: 92.09% | LR: 0.038328\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 90.66%\n",
      "Epoch: 116 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.218 | Train Acc: 92.24% | LR: 0.037566\n",
      "\t Val. Loss: 0.340 |  Val. Acc: 90.64%\n",
      "Epoch: 117 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.220 | Train Acc: 92.17% | LR: 0.036806\n",
      "\t Val. Loss: 0.324 |  Val. Acc: 90.64%\n",
      "Epoch: 118 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.218 | Train Acc: 92.23% | LR: 0.036050\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 89.89%\n",
      "Epoch: 119 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.215 | Train Acc: 92.36% | LR: 0.035298\n",
      "\t Val. Loss: 0.312 |  Val. Acc: 91.18%\n",
      "Epoch: 120 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.212 | Train Acc: 92.33% | LR: 0.034549\n",
      "\t Val. Loss: 0.330 |  Val. Acc: 90.78%\n",
      "Epoch: 121 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.213 | Train Acc: 92.46% | LR: 0.033804\n",
      "\t Val. Loss: 0.331 |  Val. Acc: 90.66%\n",
      "Epoch: 122 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.206 | Train Acc: 92.74% | LR: 0.033063\n",
      "\t Val. Loss: 0.313 |  Val. Acc: 90.90%\n",
      "Epoch: 123 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.207 | Train Acc: 92.69% | LR: 0.032326\n",
      "\t Val. Loss: 0.324 |  Val. Acc: 90.94%\n",
      "Epoch: 124 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.205 | Train Acc: 92.69% | LR: 0.031594\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 90.01%\n",
      "Epoch: 125 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.200 | Train Acc: 92.79% | LR: 0.030866\n",
      "\t Val. Loss: 0.341 |  Val. Acc: 90.74%\n",
      "Epoch: 126 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.199 | Train Acc: 92.74% | LR: 0.030143\n",
      "\t Val. Loss: 0.327 |  Val. Acc: 90.88%\n",
      "Epoch: 127 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.203 | Train Acc: 92.75% | LR: 0.029424\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 90.37%\n",
      "Epoch: 128 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.201 | Train Acc: 92.72% | LR: 0.028711\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.53%\n",
      "Epoch: 129 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.201 | Train Acc: 92.81% | LR: 0.028003\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 90.35%\n",
      "Epoch: 130 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.195 | Train Acc: 92.86% | LR: 0.027300\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 90.11%\n",
      "Epoch: 131 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.195 | Train Acc: 92.98% | LR: 0.026604\n",
      "\t Val. Loss: 0.340 |  Val. Acc: 90.70%\n",
      "Epoch: 132 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.193 | Train Acc: 93.17% | LR: 0.025912\n",
      "\t Val. Loss: 0.322 |  Val. Acc: 91.24%\n",
      "Epoch: 133 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.195 | Train Acc: 92.98% | LR: 0.025227\n",
      "\t Val. Loss: 0.319 |  Val. Acc: 91.00%\n",
      "Epoch: 134 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.188 | Train Acc: 93.22% | LR: 0.024548\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 90.64%\n",
      "Epoch: 135 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.190 | Train Acc: 93.22% | LR: 0.023875\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 90.55%\n",
      "Epoch: 136 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.186 | Train Acc: 93.39% | LR: 0.023209\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.49%\n",
      "Epoch: 137 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.184 | Train Acc: 93.44% | LR: 0.022549\n",
      "\t Val. Loss: 0.336 |  Val. Acc: 90.76%\n",
      "Epoch: 138 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.186 | Train Acc: 93.32% | LR: 0.021896\n",
      "\t Val. Loss: 0.338 |  Val. Acc: 90.76%\n",
      "Epoch: 139 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.50% | LR: 0.021250\n",
      "\t Val. Loss: 0.332 |  Val. Acc: 90.78%\n",
      "Epoch: 140 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.182 | Train Acc: 93.39% | LR: 0.020611\n",
      "\t Val. Loss: 0.335 |  Val. Acc: 90.94%\n",
      "Epoch: 141 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.181 | Train Acc: 93.55% | LR: 0.019979\n",
      "\t Val. Loss: 0.335 |  Val. Acc: 90.66%\n",
      "Epoch: 142 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.178 | Train Acc: 93.53% | LR: 0.019355\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 90.29%\n",
      "Epoch: 143 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.73% | LR: 0.018738\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 90.53%\n",
      "Epoch: 144 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.68% | LR: 0.018129\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 90.37%\n",
      "Epoch: 145 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.63% | LR: 0.017528\n",
      "\t Val. Loss: 0.338 |  Val. Acc: 90.90%\n",
      "Epoch: 146 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.59% | LR: 0.016934\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 90.39%\n",
      "Epoch: 147 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.173 | Train Acc: 93.73% | LR: 0.016349\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 90.78%\n",
      "Epoch: 148 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.172 | Train Acc: 93.74% | LR: 0.015773\n",
      "\t Val. Loss: 0.345 |  Val. Acc: 90.66%\n",
      "Epoch: 149 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.168 | Train Acc: 93.99% | LR: 0.015204\n",
      "\t Val. Loss: 0.360 |  Val. Acc: 90.74%\n",
      "Epoch: 150 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.166 | Train Acc: 94.00% | LR: 0.014645\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 91.14%\n",
      "Epoch: 151 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.166 | Train Acc: 93.89% | LR: 0.014094\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 90.92%\n",
      "Epoch: 152 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.164 | Train Acc: 94.14% | LR: 0.013552\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 91.00%\n",
      "Epoch: 153 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.167 | Train Acc: 93.91% | LR: 0.013018\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.53%\n",
      "Epoch: 154 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.166 | Train Acc: 93.90% | LR: 0.012494\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 90.92%\n",
      "Epoch: 155 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.165 | Train Acc: 94.05% | LR: 0.011980\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 90.90%\n",
      "Epoch: 156 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.164 | Train Acc: 94.00% | LR: 0.011474\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 91.16%\n",
      "Epoch: 157 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.162 | Train Acc: 94.20% | LR: 0.010978\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 91.00%\n",
      "Epoch: 158 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.159 | Train Acc: 94.22% | LR: 0.010492\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 91.28%\n",
      "Epoch: 159 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.162 | Train Acc: 94.26% | LR: 0.010016\n",
      "\t Val. Loss: 0.341 |  Val. Acc: 91.12%\n",
      "Epoch: 160 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.161 | Train Acc: 94.11% | LR: 0.009549\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 90.74%\n",
      "Epoch: 161 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.30% | LR: 0.009093\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.96%\n",
      "Epoch: 162 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.28% | LR: 0.008646\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 90.92%\n",
      "Epoch: 163 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.42% | LR: 0.008210\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 91.20%\n",
      "Epoch: 164 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.40% | LR: 0.007784\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 90.98%\n",
      "Epoch: 165 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.46% | LR: 0.007368\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.08%\n",
      "Epoch: 166 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.154 | Train Acc: 94.51% | LR: 0.006963\n",
      "\t Val. Loss: 0.336 |  Val. Acc: 91.12%\n",
      "Epoch: 167 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.36% | LR: 0.006568\n",
      "\t Val. Loss: 0.362 |  Val. Acc: 90.88%\n",
      "Epoch: 168 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.55% | LR: 0.006185\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 90.86%\n",
      "Epoch: 169 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.69% | LR: 0.005812\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 90.88%\n",
      "Epoch: 170 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.57% | LR: 0.005450\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 91.16%\n",
      "Epoch: 171 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.49% | LR: 0.005099\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.04%\n",
      "Epoch: 172 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.151 | Train Acc: 94.54% | LR: 0.004759\n",
      "\t Val. Loss: 0.369 |  Val. Acc: 90.94%\n",
      "Epoch: 173 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.151 | Train Acc: 94.48% | LR: 0.004430\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 91.36%\n",
      "Epoch: 174 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.59% | LR: 0.004112\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 91.50%\n",
      "Epoch: 175 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.71% | LR: 0.003806\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.08%\n",
      "Epoch: 176 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.59% | LR: 0.003511\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 91.24%\n",
      "Epoch: 177 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.90% | LR: 0.003228\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 91.16%\n",
      "Epoch: 178 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.151 | Train Acc: 94.62% | LR: 0.002956\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.22%\n",
      "Epoch: 179 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.149 | Train Acc: 94.59% | LR: 0.002696\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 91.16%\n",
      "Epoch: 180 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.57% | LR: 0.002447\n",
      "\t Val. Loss: 0.347 |  Val. Acc: 91.42%\n",
      "Epoch: 181 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.65% | LR: 0.002210\n",
      "\t Val. Loss: 0.347 |  Val. Acc: 91.46%\n",
      "Epoch: 182 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.66% | LR: 0.001985\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 91.26%\n",
      "Epoch: 183 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.75% | LR: 0.001772\n",
      "\t Val. Loss: 0.347 |  Val. Acc: 91.42%\n",
      "Epoch: 184 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.67% | LR: 0.001571\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 91.28%\n",
      "Epoch: 185 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.84% | LR: 0.001382\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.28%\n",
      "Epoch: 186 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.78% | LR: 0.001204\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 91.34%\n",
      "Epoch: 187 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.81% | LR: 0.001039\n",
      "\t Val. Loss: 0.368 |  Val. Acc: 90.98%\n",
      "Epoch: 188 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.79% | LR: 0.000886\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 91.22%\n",
      "Epoch: 189 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.77% | LR: 0.000745\n",
      "\t Val. Loss: 0.347 |  Val. Acc: 91.28%\n",
      "Epoch: 190 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.83% | LR: 0.000616\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 91.34%\n",
      "Epoch: 191 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.65% | LR: 0.000499\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 91.48%\n",
      "Epoch: 192 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.66% | LR: 0.000394\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 91.46%\n",
      "Epoch: 193 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.70% | LR: 0.000302\n",
      "\t Val. Loss: 0.345 |  Val. Acc: 91.38%\n",
      "Epoch: 194 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.85% | LR: 0.000222\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 91.44%\n",
      "Epoch: 195 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.86% | LR: 0.000154\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 91.44%\n",
      "Epoch: 196 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.89% | LR: 0.000099\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 91.26%\n",
      "Epoch: 197 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.71% | LR: 0.000056\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 91.26%\n",
      "Epoch: 198 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.71% | LR: 0.000025\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 91.22%\n",
      "Epoch: 199 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.79% | LR: 0.000006\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 91.55%\n",
      "Epoch: 200 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.71% | LR: 0.000000\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 91.28%\n",
      "Epoch: 201 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.86% | LR: 0.000006\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 91.28%\n",
      "Epoch: 202 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.85% | LR: 0.000025\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 91.18%\n",
      "Epoch: 203 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.87% | LR: 0.000056\n",
      "\t Val. Loss: 0.347 |  Val. Acc: 91.28%\n",
      "Epoch: 204 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.85% | LR: 0.000099\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 91.20%\n",
      "Epoch: 205 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.141 | Train Acc: 95.00% | LR: 0.000154\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 91.44%\n",
      "Epoch: 206 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.88% | LR: 0.000222\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 91.18%\n",
      "Epoch: 207 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.58% | LR: 0.000302\n",
      "\t Val. Loss: 0.345 |  Val. Acc: 91.40%\n",
      "Epoch: 208 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.92% | LR: 0.000394\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 91.04%\n",
      "Epoch: 209 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.75% | LR: 0.000499\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 91.26%\n",
      "Epoch: 210 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.84% | LR: 0.000616\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.12%\n",
      "Epoch: 211 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.92% | LR: 0.000745\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 91.40%\n",
      "Epoch: 212 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.91% | LR: 0.000886\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 91.16%\n",
      "Epoch: 213 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.70% | LR: 0.001039\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 91.32%\n",
      "Epoch: 214 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.77% | LR: 0.001204\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.28%\n",
      "Epoch: 215 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.68% | LR: 0.001382\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 91.42%\n",
      "Epoch: 216 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.78% | LR: 0.001571\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 91.42%\n",
      "Epoch: 217 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.143 | Train Acc: 94.87% | LR: 0.001772\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.16%\n",
      "Epoch: 218 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.64% | LR: 0.001985\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 91.42%\n",
      "Epoch: 219 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.80% | LR: 0.002210\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 91.14%\n",
      "Epoch: 220 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.86% | LR: 0.002447\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 91.32%\n",
      "Epoch: 221 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.82% | LR: 0.002696\n",
      "\t Val. Loss: 0.340 |  Val. Acc: 91.46%\n",
      "Epoch: 222 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.83% | LR: 0.002956\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 91.26%\n",
      "Epoch: 223 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.76% | LR: 0.003228\n",
      "\t Val. Loss: 0.360 |  Val. Acc: 90.86%\n",
      "Epoch: 224 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.54% | LR: 0.003511\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 91.28%\n",
      "Epoch: 225 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.72% | LR: 0.003806\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 91.28%\n",
      "Epoch: 226 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.71% | LR: 0.004112\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 91.28%\n",
      "Epoch: 227 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.78% | LR: 0.004430\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 91.10%\n",
      "Epoch: 228 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.65% | LR: 0.004759\n",
      "\t Val. Loss: 0.363 |  Val. Acc: 91.00%\n",
      "Epoch: 229 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.72% | LR: 0.005099\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 91.08%\n",
      "Epoch: 230 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.144 | Train Acc: 94.68% | LR: 0.005450\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 91.18%\n",
      "Epoch: 231 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.66% | LR: 0.005812\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 90.94%\n",
      "Epoch: 232 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.73% | LR: 0.006185\n",
      "\t Val. Loss: 0.348 |  Val. Acc: 91.28%\n",
      "Epoch: 233 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.73% | LR: 0.006568\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 91.26%\n",
      "Epoch: 234 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.78% | LR: 0.006963\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 91.08%\n",
      "Epoch: 235 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.63% | LR: 0.007368\n",
      "\t Val. Loss: 0.347 |  Val. Acc: 91.46%\n",
      "Epoch: 236 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.68% | LR: 0.007784\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 90.92%\n",
      "Epoch: 237 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.68% | LR: 0.008210\n",
      "\t Val. Loss: 0.345 |  Val. Acc: 91.48%\n",
      "Epoch: 238 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.149 | Train Acc: 94.58% | LR: 0.008646\n",
      "\t Val. Loss: 0.363 |  Val. Acc: 91.14%\n",
      "Epoch: 239 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.149 | Train Acc: 94.58% | LR: 0.009093\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 90.96%\n",
      "Epoch: 240 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.151 | Train Acc: 94.60% | LR: 0.009549\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 91.18%\n",
      "Epoch: 241 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.149 | Train Acc: 94.64% | LR: 0.010016\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 91.44%\n",
      "Epoch: 242 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.59% | LR: 0.010492\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 91.26%\n",
      "Epoch: 243 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.149 | Train Acc: 94.57% | LR: 0.010978\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 91.02%\n",
      "Epoch: 244 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.74% | LR: 0.011474\n",
      "\t Val. Loss: 0.349 |  Val. Acc: 91.02%\n",
      "Epoch: 245 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.79% | LR: 0.011980\n",
      "\t Val. Loss: 0.364 |  Val. Acc: 91.00%\n",
      "Epoch: 246 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.60% | LR: 0.012494\n",
      "\t Val. Loss: 0.377 |  Val. Acc: 91.18%\n",
      "Epoch: 247 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.58% | LR: 0.013018\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 91.10%\n",
      "Epoch: 248 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.58% | LR: 0.013552\n",
      "\t Val. Loss: 0.341 |  Val. Acc: 91.44%\n",
      "Epoch: 249 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.51% | LR: 0.014094\n",
      "\t Val. Loss: 0.376 |  Val. Acc: 90.72%\n",
      "Epoch: 250 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.41% | LR: 0.014645\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 90.98%\n",
      "Epoch: 251 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.54% | LR: 0.015204\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 91.06%\n",
      "Epoch: 252 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.150 | Train Acc: 94.61% | LR: 0.015773\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 91.10%\n",
      "Epoch: 253 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.47% | LR: 0.016349\n",
      "\t Val. Loss: 0.360 |  Val. Acc: 90.92%\n",
      "Epoch: 254 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.53% | LR: 0.016934\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 91.26%\n",
      "Epoch: 255 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.56% | LR: 0.017528\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 91.08%\n",
      "Epoch: 256 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.36% | LR: 0.018129\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 91.28%\n",
      "Epoch: 257 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.151 | Train Acc: 94.58% | LR: 0.018738\n",
      "\t Val. Loss: 0.360 |  Val. Acc: 90.80%\n",
      "Epoch: 258 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.154 | Train Acc: 94.43% | LR: 0.019355\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 91.08%\n",
      "Epoch: 259 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.158 | Train Acc: 94.29% | LR: 0.019979\n",
      "\t Val. Loss: 0.351 |  Val. Acc: 90.92%\n",
      "Epoch: 260 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.54% | LR: 0.020611\n",
      "\t Val. Loss: 0.369 |  Val. Acc: 91.06%\n",
      "Epoch: 261 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.160 | Train Acc: 94.23% | LR: 0.021250\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 90.94%\n",
      "Epoch: 262 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.154 | Train Acc: 94.44% | LR: 0.021896\n",
      "\t Val. Loss: 0.368 |  Val. Acc: 90.68%\n",
      "Epoch: 263 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.39% | LR: 0.022549\n",
      "\t Val. Loss: 0.368 |  Val. Acc: 90.84%\n",
      "Epoch: 264 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.38% | LR: 0.023209\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 90.80%\n",
      "Epoch: 265 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.34% | LR: 0.023875\n",
      "\t Val. Loss: 0.385 |  Val. Acc: 90.57%\n",
      "Epoch: 266 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.36% | LR: 0.024548\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 90.88%\n",
      "Epoch: 267 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.158 | Train Acc: 94.33% | LR: 0.025227\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 90.92%\n",
      "Epoch: 268 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.36% | LR: 0.025912\n",
      "\t Val. Loss: 0.364 |  Val. Acc: 90.94%\n",
      "Epoch: 269 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.160 | Train Acc: 94.28% | LR: 0.026604\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.86%\n",
      "Epoch: 270 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.160 | Train Acc: 94.26% | LR: 0.027300\n",
      "\t Val. Loss: 0.361 |  Val. Acc: 90.88%\n",
      "Epoch: 271 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.161 | Train Acc: 94.17% | LR: 0.028003\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 91.14%\n",
      "Epoch: 272 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.161 | Train Acc: 94.11% | LR: 0.028711\n",
      "\t Val. Loss: 0.344 |  Val. Acc: 91.30%\n",
      "Epoch: 273 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.168 | Train Acc: 93.94% | LR: 0.029424\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 91.10%\n",
      "Epoch: 274 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.166 | Train Acc: 93.99% | LR: 0.030143\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 90.78%\n",
      "Epoch: 275 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.169 | Train Acc: 93.93% | LR: 0.030866\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 90.88%\n",
      "Epoch: 276 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.168 | Train Acc: 93.93% | LR: 0.031594\n",
      "\t Val. Loss: 0.369 |  Val. Acc: 90.29%\n",
      "Epoch: 277 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.163 | Train Acc: 94.13% | LR: 0.032326\n",
      "\t Val. Loss: 0.315 |  Val. Acc: 91.44%\n",
      "Epoch: 278 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.166 | Train Acc: 93.95% | LR: 0.033063\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.92%\n",
      "Epoch: 279 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.164 | Train Acc: 94.06% | LR: 0.033804\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 90.55%\n",
      "Epoch: 280 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.168 | Train Acc: 93.93% | LR: 0.034549\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 90.88%\n",
      "Epoch: 281 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.169 | Train Acc: 93.80% | LR: 0.035298\n",
      "\t Val. Loss: 0.330 |  Val. Acc: 91.30%\n",
      "Epoch: 282 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.168 | Train Acc: 94.01% | LR: 0.036050\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 91.12%\n",
      "Epoch: 283 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.170 | Train Acc: 94.00% | LR: 0.036806\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 90.37%\n",
      "Epoch: 284 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.175 | Train Acc: 93.73% | LR: 0.037566\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 91.04%\n",
      "Epoch: 285 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.166 | Train Acc: 94.00% | LR: 0.038328\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 90.68%\n",
      "Epoch: 286 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.171 | Train Acc: 93.94% | LR: 0.039093\n",
      "\t Val. Loss: 0.390 |  Val. Acc: 89.54%\n",
      "Epoch: 287 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.168 | Train Acc: 94.01% | LR: 0.039861\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 90.61%\n",
      "Epoch: 288 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.172 | Train Acc: 93.90% | LR: 0.040631\n",
      "\t Val. Loss: 0.331 |  Val. Acc: 91.26%\n",
      "Epoch: 289 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.172 | Train Acc: 93.69% | LR: 0.041404\n",
      "\t Val. Loss: 0.353 |  Val. Acc: 90.49%\n",
      "Epoch: 290 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.175 | Train Acc: 93.71% | LR: 0.042178\n",
      "\t Val. Loss: 0.355 |  Val. Acc: 90.57%\n",
      "Epoch: 291 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.170 | Train Acc: 93.91% | LR: 0.042955\n",
      "\t Val. Loss: 0.342 |  Val. Acc: 91.12%\n",
      "Epoch: 292 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.175 | Train Acc: 93.82% | LR: 0.043733\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 90.57%\n",
      "Epoch: 293 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.84% | LR: 0.044513\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 90.82%\n",
      "Epoch: 294 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.55% | LR: 0.045295\n",
      "\t Val. Loss: 0.360 |  Val. Acc: 90.43%\n",
      "Epoch: 295 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.59% | LR: 0.046077\n",
      "\t Val. Loss: 0.382 |  Val. Acc: 90.29%\n",
      "Epoch: 296 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.176 | Train Acc: 93.71% | LR: 0.046860\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 90.68%\n",
      "Epoch: 297 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.178 | Train Acc: 93.59% | LR: 0.047645\n",
      "\t Val. Loss: 0.366 |  Val. Acc: 90.35%\n",
      "Epoch: 298 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.178 | Train Acc: 93.53% | LR: 0.048429\n",
      "\t Val. Loss: 0.379 |  Val. Acc: 89.97%\n",
      "Epoch: 299 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.61% | LR: 0.049215\n",
      "\t Val. Loss: 0.356 |  Val. Acc: 90.64%\n",
      "Epoch: 300 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.69% | LR: 0.050000\n",
      "\t Val. Loss: 0.364 |  Val. Acc: 90.45%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "valid_acc_history = []\n",
    "valid_loss_history = []\n",
    "lr_epoch = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "   \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    \n",
    "    scheduler.step()\n",
    "    lr_now = lr_now = optimizer.param_groups[0]['lr']\n",
    "    lr_epoch.append(lr_now)\n",
    "\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "        \n",
    "    end_time = time.time()\n",
    "\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | LR: {lr_now:.6f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_loss_history.append( train_loss)\n",
    "    valid_acc_history.append(valid_acc)\n",
    "    valid_loss_history.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f23f805eee0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,(ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "ax1.plot(range(num_epochs), train_loss_history, '--r')\n",
    "ax1.plot(range(num_epochs), valid_loss_history, '-g')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend(['train', 'valid'])\n",
    "\n",
    "ax2.plot(range(num_epochs), train_acc_history, '--r')\n",
    "ax2.plot(range(num_epochs), valid_acc_history, '-g')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_xlabel('Accuracy')\n",
    "ax1.legend(['train', 'valid'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw3prob5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
