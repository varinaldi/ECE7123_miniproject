{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "\n",
    "from model import ResidualBlock, ResNet\n",
    "from train_eval_util import train, evaluate, calculate_accuracy, epoch_time\n",
    "from getCIFAR10 import train_data, valid_data, test_data\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size= BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_iterator =  DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_iterator =  DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers: 32\n",
      "Total number of parameters: 466906\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(ResidualBlock, [5, 5, 5]).to(device)\n",
    "\n",
    "\n",
    "total_layers = sum([1 for _ in model.modules() \n",
    "    if isinstance(_, nn.Conv2d) or isinstance(_, nn.Linear)]) - 2 # subtract input and output layers\n",
    "    \n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total number of layers: {total_layers}\")\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 1.538 | Train Acc: 42.52%\n",
      "\t Val. Loss: 1.698 |  Val. Acc: 43.46%\n",
      "Epoch: 02 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 1.171 | Train Acc: 57.52%\n",
      "\t Val. Loss: 1.232 |  Val. Acc: 57.99%\n",
      "Epoch: 03 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 1.027 | Train Acc: 63.08%\n",
      "\t Val. Loss: 1.165 |  Val. Acc: 60.33%\n",
      "Epoch: 04 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.934 | Train Acc: 66.79%\n",
      "\t Val. Loss: 1.202 |  Val. Acc: 62.15%\n",
      "Epoch: 05 | Epoch Time: 0m 43s\n",
      "\tTrain Loss: 0.860 | Train Acc: 69.58%\n",
      "\t Val. Loss: 0.859 |  Val. Acc: 69.80%\n",
      "Epoch: 06 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.802 | Train Acc: 71.59%\n",
      "\t Val. Loss: 0.854 |  Val. Acc: 70.06%\n",
      "Epoch: 07 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.755 | Train Acc: 73.39%\n",
      "\t Val. Loss: 1.229 |  Val. Acc: 60.86%\n",
      "Epoch: 08 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.709 | Train Acc: 75.13%\n",
      "\t Val. Loss: 0.803 |  Val. Acc: 72.23%\n",
      "Epoch: 09 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.668 | Train Acc: 76.67%\n",
      "\t Val. Loss: 0.778 |  Val. Acc: 73.42%\n",
      "Epoch: 10 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.642 | Train Acc: 77.70%\n",
      "\t Val. Loss: 0.814 |  Val. Acc: 72.99%\n",
      "Epoch: 11 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.604 | Train Acc: 78.94%\n",
      "\t Val. Loss: 0.759 |  Val. Acc: 74.51%\n",
      "Epoch: 12 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.589 | Train Acc: 79.41%\n",
      "\t Val. Loss: 0.751 |  Val. Acc: 75.84%\n",
      "Epoch: 13 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.572 | Train Acc: 80.05%\n",
      "\t Val. Loss: 0.690 |  Val. Acc: 76.93%\n",
      "Epoch: 14 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.550 | Train Acc: 80.77%\n",
      "\t Val. Loss: 0.761 |  Val. Acc: 74.34%\n",
      "Epoch: 15 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.528 | Train Acc: 81.45%\n",
      "\t Val. Loss: 0.755 |  Val. Acc: 76.17%\n",
      "Epoch: 16 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.514 | Train Acc: 82.11%\n",
      "\t Val. Loss: 0.699 |  Val. Acc: 76.86%\n",
      "Epoch: 17 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.504 | Train Acc: 82.36%\n",
      "\t Val. Loss: 0.660 |  Val. Acc: 78.38%\n",
      "Epoch: 18 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.485 | Train Acc: 83.04%\n",
      "\t Val. Loss: 0.710 |  Val. Acc: 77.46%\n",
      "Epoch: 19 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.475 | Train Acc: 83.55%\n",
      "\t Val. Loss: 0.569 |  Val. Acc: 80.90%\n",
      "Epoch: 20 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.462 | Train Acc: 83.85%\n",
      "\t Val. Loss: 0.547 |  Val. Acc: 81.27%\n",
      "Epoch: 21 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.455 | Train Acc: 84.17%\n",
      "\t Val. Loss: 0.568 |  Val. Acc: 81.66%\n",
      "Epoch: 22 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.440 | Train Acc: 84.88%\n",
      "\t Val. Loss: 0.510 |  Val. Acc: 83.12%\n",
      "Epoch: 23 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.427 | Train Acc: 85.13%\n",
      "\t Val. Loss: 0.544 |  Val. Acc: 81.37%\n",
      "Epoch: 24 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.416 | Train Acc: 85.60%\n",
      "\t Val. Loss: 0.646 |  Val. Acc: 80.53%\n",
      "Epoch: 25 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.411 | Train Acc: 85.68%\n",
      "\t Val. Loss: 0.568 |  Val. Acc: 80.62%\n",
      "Epoch: 26 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.403 | Train Acc: 85.99%\n",
      "\t Val. Loss: 0.507 |  Val. Acc: 82.85%\n",
      "Epoch: 27 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.393 | Train Acc: 86.26%\n",
      "\t Val. Loss: 0.588 |  Val. Acc: 81.52%\n",
      "Epoch: 28 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.388 | Train Acc: 86.38%\n",
      "\t Val. Loss: 0.535 |  Val. Acc: 83.09%\n",
      "Epoch: 29 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.378 | Train Acc: 86.89%\n",
      "\t Val. Loss: 0.676 |  Val. Acc: 80.59%\n",
      "Epoch: 30 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.374 | Train Acc: 86.91%\n",
      "\t Val. Loss: 0.490 |  Val. Acc: 84.49%\n",
      "Epoch: 31 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.369 | Train Acc: 87.26%\n",
      "\t Val. Loss: 0.633 |  Val. Acc: 80.94%\n",
      "Epoch: 32 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.356 | Train Acc: 87.68%\n",
      "\t Val. Loss: 0.469 |  Val. Acc: 84.38%\n",
      "Epoch: 33 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.350 | Train Acc: 87.82%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 83.89%\n",
      "Epoch: 34 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.345 | Train Acc: 87.90%\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 84.02%\n",
      "Epoch: 35 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.338 | Train Acc: 88.23%\n",
      "\t Val. Loss: 0.569 |  Val. Acc: 82.38%\n",
      "Epoch: 36 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.327 | Train Acc: 88.56%\n",
      "\t Val. Loss: 0.473 |  Val. Acc: 84.36%\n",
      "Epoch: 37 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.323 | Train Acc: 88.61%\n",
      "\t Val. Loss: 0.547 |  Val. Acc: 83.61%\n",
      "Epoch: 38 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.320 | Train Acc: 88.79%\n",
      "\t Val. Loss: 0.528 |  Val. Acc: 83.11%\n",
      "Epoch: 39 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.315 | Train Acc: 88.92%\n",
      "\t Val. Loss: 0.525 |  Val. Acc: 83.52%\n",
      "Epoch: 40 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.310 | Train Acc: 89.17%\n",
      "\t Val. Loss: 0.453 |  Val. Acc: 85.55%\n",
      "Epoch: 41 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.301 | Train Acc: 89.46%\n",
      "\t Val. Loss: 0.488 |  Val. Acc: 84.63%\n",
      "Epoch: 42 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.297 | Train Acc: 89.67%\n",
      "\t Val. Loss: 0.433 |  Val. Acc: 85.59%\n",
      "Epoch: 43 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.288 | Train Acc: 89.90%\n",
      "\t Val. Loss: 0.495 |  Val. Acc: 85.20%\n",
      "Epoch: 44 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.288 | Train Acc: 89.89%\n",
      "\t Val. Loss: 0.475 |  Val. Acc: 85.06%\n",
      "Epoch: 45 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.282 | Train Acc: 90.08%\n",
      "\t Val. Loss: 0.519 |  Val. Acc: 83.91%\n",
      "Epoch: 46 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.278 | Train Acc: 90.16%\n",
      "\t Val. Loss: 0.452 |  Val. Acc: 85.82%\n",
      "Epoch: 47 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.278 | Train Acc: 90.19%\n",
      "\t Val. Loss: 0.493 |  Val. Acc: 85.06%\n",
      "Epoch: 48 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.270 | Train Acc: 90.51%\n",
      "\t Val. Loss: 0.708 |  Val. Acc: 80.41%\n",
      "Epoch: 49 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.271 | Train Acc: 90.32%\n",
      "\t Val. Loss: 0.518 |  Val. Acc: 83.85%\n",
      "Epoch: 50 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.262 | Train Acc: 90.80%\n",
      "\t Val. Loss: 0.540 |  Val. Acc: 84.02%\n",
      "Epoch: 51 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.261 | Train Acc: 90.72%\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 86.05%\n",
      "Epoch: 52 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.249 | Train Acc: 91.18%\n",
      "\t Val. Loss: 0.465 |  Val. Acc: 85.74%\n",
      "Epoch: 53 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.248 | Train Acc: 91.36%\n",
      "\t Val. Loss: 0.443 |  Val. Acc: 86.09%\n",
      "Epoch: 54 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.247 | Train Acc: 91.16%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 85.62%\n",
      "Epoch: 55 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.245 | Train Acc: 91.31%\n",
      "\t Val. Loss: 0.502 |  Val. Acc: 85.37%\n",
      "Epoch: 56 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.239 | Train Acc: 91.59%\n",
      "\t Val. Loss: 0.464 |  Val. Acc: 85.90%\n",
      "Epoch: 57 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.236 | Train Acc: 91.71%\n",
      "\t Val. Loss: 0.448 |  Val. Acc: 85.61%\n",
      "Epoch: 58 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.231 | Train Acc: 91.91%\n",
      "\t Val. Loss: 0.433 |  Val. Acc: 86.72%\n",
      "Epoch: 59 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.228 | Train Acc: 91.92%\n",
      "\t Val. Loss: 0.445 |  Val. Acc: 85.88%\n",
      "Epoch: 60 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.221 | Train Acc: 92.30%\n",
      "\t Val. Loss: 0.483 |  Val. Acc: 86.02%\n",
      "Epoch: 61 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.223 | Train Acc: 92.16%\n",
      "\t Val. Loss: 0.496 |  Val. Acc: 85.51%\n",
      "Epoch: 62 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.220 | Train Acc: 92.24%\n",
      "\t Val. Loss: 0.457 |  Val. Acc: 86.29%\n",
      "Epoch: 63 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.215 | Train Acc: 92.47%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 85.37%\n",
      "Epoch: 64 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.211 | Train Acc: 92.57%\n",
      "\t Val. Loss: 0.493 |  Val. Acc: 85.74%\n",
      "Epoch: 65 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.207 | Train Acc: 92.75%\n",
      "\t Val. Loss: 0.501 |  Val. Acc: 85.96%\n",
      "Epoch: 66 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.206 | Train Acc: 92.71%\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 86.39%\n",
      "Epoch: 67 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.204 | Train Acc: 92.86%\n",
      "\t Val. Loss: 0.545 |  Val. Acc: 84.96%\n",
      "Epoch: 68 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.198 | Train Acc: 92.94%\n",
      "\t Val. Loss: 0.527 |  Val. Acc: 85.47%\n",
      "Epoch: 69 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.198 | Train Acc: 93.01%\n",
      "\t Val. Loss: 0.463 |  Val. Acc: 86.43%\n",
      "Epoch: 70 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.193 | Train Acc: 93.15%\n",
      "\t Val. Loss: 0.499 |  Val. Acc: 85.68%\n",
      "Epoch: 71 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.191 | Train Acc: 93.20%\n",
      "\t Val. Loss: 0.454 |  Val. Acc: 86.29%\n",
      "Epoch: 72 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.192 | Train Acc: 93.31%\n",
      "\t Val. Loss: 0.458 |  Val. Acc: 86.56%\n",
      "Epoch: 73 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.194 | Train Acc: 93.15%\n",
      "\t Val. Loss: 0.645 |  Val. Acc: 83.96%\n",
      "Epoch: 74 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.188 | Train Acc: 93.40%\n",
      "\t Val. Loss: 0.474 |  Val. Acc: 87.27%\n",
      "Epoch: 75 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.179 | Train Acc: 93.79%\n",
      "\t Val. Loss: 0.462 |  Val. Acc: 86.11%\n",
      "Epoch: 76 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.183 | Train Acc: 93.53%\n",
      "\t Val. Loss: 0.606 |  Val. Acc: 83.87%\n",
      "Epoch: 77 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.179 | Train Acc: 93.64%\n",
      "\t Val. Loss: 0.446 |  Val. Acc: 87.30%\n",
      "Epoch: 78 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.178 | Train Acc: 93.55%\n",
      "\t Val. Loss: 0.603 |  Val. Acc: 84.67%\n",
      "Epoch: 79 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.173 | Train Acc: 93.79%\n",
      "\t Val. Loss: 0.447 |  Val. Acc: 86.70%\n",
      "Epoch: 80 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.173 | Train Acc: 93.92%\n",
      "\t Val. Loss: 0.413 |  Val. Acc: 87.09%\n",
      "Epoch: 81 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.169 | Train Acc: 94.06%\n",
      "\t Val. Loss: 0.497 |  Val. Acc: 86.05%\n",
      "Epoch: 82 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.169 | Train Acc: 94.09%\n",
      "\t Val. Loss: 0.548 |  Val. Acc: 85.37%\n",
      "Epoch: 83 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.165 | Train Acc: 94.20%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 86.58%\n",
      "Epoch: 84 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.160 | Train Acc: 94.30%\n",
      "\t Val. Loss: 0.522 |  Val. Acc: 86.60%\n",
      "Epoch: 85 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.163 | Train Acc: 94.16%\n",
      "\t Val. Loss: 0.452 |  Val. Acc: 87.73%\n",
      "Epoch: 86 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.161 | Train Acc: 94.21%\n",
      "\t Val. Loss: 0.468 |  Val. Acc: 87.32%\n",
      "Epoch: 87 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.159 | Train Acc: 94.36%\n",
      "\t Val. Loss: 0.473 |  Val. Acc: 87.70%\n",
      "Epoch: 88 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.158 | Train Acc: 94.30%\n",
      "\t Val. Loss: 0.463 |  Val. Acc: 86.93%\n",
      "Epoch: 89 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.153 | Train Acc: 94.60%\n",
      "\t Val. Loss: 0.490 |  Val. Acc: 86.25%\n",
      "Epoch: 90 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.51%\n",
      "\t Val. Loss: 0.452 |  Val. Acc: 87.99%\n",
      "Epoch: 91 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.151 | Train Acc: 94.67%\n",
      "\t Val. Loss: 0.518 |  Val. Acc: 86.46%\n",
      "Epoch: 92 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.149 | Train Acc: 94.73%\n",
      "\t Val. Loss: 0.473 |  Val. Acc: 87.60%\n",
      "Epoch: 93 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.146 | Train Acc: 94.78%\n",
      "\t Val. Loss: 0.692 |  Val. Acc: 84.20%\n",
      "Epoch: 94 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.148 | Train Acc: 94.74%\n",
      "\t Val. Loss: 0.495 |  Val. Acc: 87.64%\n",
      "Epoch: 95 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.147 | Train Acc: 94.80%\n",
      "\t Val. Loss: 0.548 |  Val. Acc: 85.62%\n",
      "Epoch: 96 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.143 | Train Acc: 95.02%\n",
      "\t Val. Loss: 0.510 |  Val. Acc: 86.52%\n",
      "Epoch: 97 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.142 | Train Acc: 95.00%\n",
      "\t Val. Loss: 0.485 |  Val. Acc: 87.25%\n",
      "Epoch: 98 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.137 | Train Acc: 95.09%\n",
      "\t Val. Loss: 0.457 |  Val. Acc: 87.40%\n",
      "Epoch: 99 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.133 | Train Acc: 95.22%\n",
      "\t Val. Loss: 0.504 |  Val. Acc: 86.70%\n",
      "Epoch: 100 | Epoch Time: 0m 41s\n",
      "\tTrain Loss: 0.140 | Train Acc: 95.05%\n",
      "\t Val. Loss: 0.458 |  Val. Acc: 87.30%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "valid_acc_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "        \n",
    "    end_time = time.time()\n",
    "\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_loss_history.append( train_loss)\n",
    "    valid_acc_history.append(valid_acc)\n",
    "    valid_loss_history.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'resnet32.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers: 20\n",
      "Total number of parameters: 272474\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(ResidualBlock, [3, 3, 3]).to(device)\n",
    "\n",
    "\n",
    "total_layers = sum([1 for _ in model.modules() \n",
    "    if isinstance(_, nn.Conv2d) or isinstance(_, nn.Linear)]) - 2 # subtract input and output layers\n",
    "    \n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total number of layers: {total_layers}\")\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 29s\n",
      "\tTrain Loss: 1.539 | Train Acc: 42.73%\n",
      "\t Val. Loss: 1.435 |  Val. Acc: 48.40%\n",
      "Epoch: 02 | Epoch Time: 0m 29s\n",
      "\tTrain Loss: 1.155 | Train Acc: 58.25%\n",
      "\t Val. Loss: 1.275 |  Val. Acc: 54.86%\n",
      "Epoch: 03 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 1.010 | Train Acc: 63.58%\n",
      "\t Val. Loss: 1.100 |  Val. Acc: 61.39%\n",
      "Epoch: 04 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.926 | Train Acc: 66.87%\n",
      "\t Val. Loss: 1.083 |  Val. Acc: 62.38%\n",
      "Epoch: 05 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.853 | Train Acc: 69.65%\n",
      "\t Val. Loss: 1.008 |  Val. Acc: 64.49%\n",
      "Epoch: 06 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.795 | Train Acc: 71.88%\n",
      "\t Val. Loss: 1.150 |  Val. Acc: 63.54%\n",
      "Epoch: 07 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.749 | Train Acc: 73.48%\n",
      "\t Val. Loss: 0.919 |  Val. Acc: 68.01%\n",
      "Epoch: 08 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.708 | Train Acc: 75.00%\n",
      "\t Val. Loss: 1.044 |  Val. Acc: 66.68%\n",
      "Epoch: 09 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.673 | Train Acc: 76.27%\n",
      "\t Val. Loss: 0.830 |  Val. Acc: 71.23%\n",
      "Epoch: 10 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.650 | Train Acc: 77.10%\n",
      "\t Val. Loss: 1.088 |  Val. Acc: 67.30%\n",
      "Epoch: 11 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.616 | Train Acc: 78.27%\n",
      "\t Val. Loss: 0.789 |  Val. Acc: 72.17%\n",
      "Epoch: 12 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.594 | Train Acc: 79.33%\n",
      "\t Val. Loss: 0.727 |  Val. Acc: 76.13%\n",
      "Epoch: 13 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.572 | Train Acc: 79.94%\n",
      "\t Val. Loss: 0.610 |  Val. Acc: 78.89%\n",
      "Epoch: 14 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.557 | Train Acc: 80.87%\n",
      "\t Val. Loss: 0.674 |  Val. Acc: 77.71%\n",
      "Epoch: 15 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.541 | Train Acc: 81.15%\n",
      "\t Val. Loss: 0.627 |  Val. Acc: 78.01%\n",
      "Epoch: 16 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.525 | Train Acc: 81.92%\n",
      "\t Val. Loss: 0.573 |  Val. Acc: 80.20%\n",
      "Epoch: 17 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.513 | Train Acc: 82.35%\n",
      "\t Val. Loss: 0.780 |  Val. Acc: 75.37%\n",
      "Epoch: 18 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.498 | Train Acc: 82.78%\n",
      "\t Val. Loss: 0.579 |  Val. Acc: 80.76%\n",
      "Epoch: 19 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.481 | Train Acc: 83.40%\n",
      "\t Val. Loss: 0.670 |  Val. Acc: 76.74%\n",
      "Epoch: 20 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.473 | Train Acc: 83.58%\n",
      "\t Val. Loss: 0.650 |  Val. Acc: 78.69%\n",
      "Epoch: 21 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.466 | Train Acc: 83.92%\n",
      "\t Val. Loss: 0.578 |  Val. Acc: 79.88%\n",
      "Epoch: 22 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.451 | Train Acc: 84.26%\n",
      "\t Val. Loss: 0.553 |  Val. Acc: 81.31%\n",
      "Epoch: 23 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.444 | Train Acc: 84.45%\n",
      "\t Val. Loss: 0.562 |  Val. Acc: 80.61%\n",
      "Epoch: 24 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.430 | Train Acc: 85.04%\n",
      "\t Val. Loss: 0.499 |  Val. Acc: 83.01%\n",
      "Epoch: 25 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.426 | Train Acc: 85.10%\n",
      "\t Val. Loss: 0.687 |  Val. Acc: 79.55%\n",
      "Epoch: 26 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.415 | Train Acc: 85.68%\n",
      "\t Val. Loss: 0.523 |  Val. Acc: 82.29%\n",
      "Epoch: 27 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.410 | Train Acc: 85.84%\n",
      "\t Val. Loss: 0.587 |  Val. Acc: 80.74%\n",
      "Epoch: 28 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.397 | Train Acc: 86.35%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 82.54%\n",
      "Epoch: 29 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.392 | Train Acc: 86.28%\n",
      "\t Val. Loss: 0.561 |  Val. Acc: 81.48%\n",
      "Epoch: 30 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.387 | Train Acc: 86.43%\n",
      "\t Val. Loss: 0.628 |  Val. Acc: 78.89%\n",
      "Epoch: 31 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.380 | Train Acc: 86.90%\n",
      "\t Val. Loss: 0.605 |  Val. Acc: 80.86%\n",
      "Epoch: 32 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.372 | Train Acc: 87.10%\n",
      "\t Val. Loss: 0.535 |  Val. Acc: 82.73%\n",
      "Epoch: 33 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.360 | Train Acc: 87.49%\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 83.40%\n",
      "Epoch: 34 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.366 | Train Acc: 87.40%\n",
      "\t Val. Loss: 0.474 |  Val. Acc: 83.87%\n",
      "Epoch: 35 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.350 | Train Acc: 87.63%\n",
      "\t Val. Loss: 0.485 |  Val. Acc: 84.04%\n",
      "Epoch: 36 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.346 | Train Acc: 87.97%\n",
      "\t Val. Loss: 0.710 |  Val. Acc: 78.38%\n",
      "Epoch: 37 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.342 | Train Acc: 88.02%\n",
      "\t Val. Loss: 0.497 |  Val. Acc: 83.34%\n",
      "Epoch: 38 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.337 | Train Acc: 88.28%\n",
      "\t Val. Loss: 0.697 |  Val. Acc: 79.06%\n",
      "Epoch: 39 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.331 | Train Acc: 88.43%\n",
      "\t Val. Loss: 0.512 |  Val. Acc: 83.18%\n",
      "Epoch: 40 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.325 | Train Acc: 88.69%\n",
      "\t Val. Loss: 0.594 |  Val. Acc: 81.23%\n",
      "Epoch: 41 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.320 | Train Acc: 88.95%\n",
      "\t Val. Loss: 0.594 |  Val. Acc: 81.62%\n",
      "Epoch: 42 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.320 | Train Acc: 88.68%\n",
      "\t Val. Loss: 0.585 |  Val. Acc: 82.52%\n",
      "Epoch: 43 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.312 | Train Acc: 89.09%\n",
      "\t Val. Loss: 0.531 |  Val. Acc: 83.44%\n",
      "Epoch: 44 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.306 | Train Acc: 89.36%\n",
      "\t Val. Loss: 0.519 |  Val. Acc: 83.32%\n",
      "Epoch: 45 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.305 | Train Acc: 89.34%\n",
      "\t Val. Loss: 0.561 |  Val. Acc: 82.48%\n",
      "Epoch: 46 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.306 | Train Acc: 89.27%\n",
      "\t Val. Loss: 0.450 |  Val. Acc: 85.37%\n",
      "Epoch: 47 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.294 | Train Acc: 89.85%\n",
      "\t Val. Loss: 0.459 |  Val. Acc: 84.80%\n",
      "Epoch: 48 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.290 | Train Acc: 89.92%\n",
      "\t Val. Loss: 0.543 |  Val. Acc: 82.54%\n",
      "Epoch: 49 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.284 | Train Acc: 90.03%\n",
      "\t Val. Loss: 0.499 |  Val. Acc: 83.71%\n",
      "Epoch: 50 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.283 | Train Acc: 90.15%\n",
      "\t Val. Loss: 0.517 |  Val. Acc: 84.59%\n",
      "Epoch: 51 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.280 | Train Acc: 90.19%\n",
      "\t Val. Loss: 0.480 |  Val. Acc: 84.30%\n",
      "Epoch: 52 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.278 | Train Acc: 90.38%\n",
      "\t Val. Loss: 0.503 |  Val. Acc: 84.53%\n",
      "Epoch: 53 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.272 | Train Acc: 90.55%\n",
      "\t Val. Loss: 0.548 |  Val. Acc: 82.56%\n",
      "Epoch: 54 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.268 | Train Acc: 90.62%\n",
      "\t Val. Loss: 0.453 |  Val. Acc: 85.74%\n",
      "Epoch: 55 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.262 | Train Acc: 90.72%\n",
      "\t Val. Loss: 0.599 |  Val. Acc: 82.77%\n",
      "Epoch: 56 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.261 | Train Acc: 90.89%\n",
      "\t Val. Loss: 0.624 |  Val. Acc: 82.66%\n",
      "Epoch: 57 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.258 | Train Acc: 91.08%\n",
      "\t Val. Loss: 0.540 |  Val. Acc: 83.52%\n",
      "Epoch: 58 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.250 | Train Acc: 91.08%\n",
      "\t Val. Loss: 0.534 |  Val. Acc: 83.75%\n",
      "Epoch: 59 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.249 | Train Acc: 91.25%\n",
      "\t Val. Loss: 0.440 |  Val. Acc: 86.00%\n",
      "Epoch: 60 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.247 | Train Acc: 91.34%\n",
      "\t Val. Loss: 0.442 |  Val. Acc: 85.10%\n",
      "Epoch: 61 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.242 | Train Acc: 91.58%\n",
      "\t Val. Loss: 0.568 |  Val. Acc: 83.05%\n",
      "Epoch: 62 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.246 | Train Acc: 91.46%\n",
      "\t Val. Loss: 0.528 |  Val. Acc: 83.85%\n",
      "Epoch: 63 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.234 | Train Acc: 91.71%\n",
      "\t Val. Loss: 0.453 |  Val. Acc: 86.23%\n",
      "Epoch: 64 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.233 | Train Acc: 91.76%\n",
      "\t Val. Loss: 0.565 |  Val. Acc: 83.85%\n",
      "Epoch: 65 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.237 | Train Acc: 91.69%\n",
      "\t Val. Loss: 0.480 |  Val. Acc: 85.39%\n",
      "Epoch: 66 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.230 | Train Acc: 91.89%\n",
      "\t Val. Loss: 0.458 |  Val. Acc: 85.27%\n",
      "Epoch: 67 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.223 | Train Acc: 92.17%\n",
      "\t Val. Loss: 0.547 |  Val. Acc: 83.77%\n",
      "Epoch: 68 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.223 | Train Acc: 92.17%\n",
      "\t Val. Loss: 0.505 |  Val. Acc: 85.64%\n",
      "Epoch: 69 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.220 | Train Acc: 92.21%\n",
      "\t Val. Loss: 0.465 |  Val. Acc: 85.88%\n",
      "Epoch: 70 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.216 | Train Acc: 92.34%\n",
      "\t Val. Loss: 0.610 |  Val. Acc: 82.68%\n",
      "Epoch: 71 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.217 | Train Acc: 92.29%\n",
      "\t Val. Loss: 0.465 |  Val. Acc: 86.17%\n",
      "Epoch: 72 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.209 | Train Acc: 92.51%\n",
      "\t Val. Loss: 0.525 |  Val. Acc: 85.00%\n",
      "Epoch: 73 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.210 | Train Acc: 92.66%\n",
      "\t Val. Loss: 0.534 |  Val. Acc: 85.27%\n",
      "Epoch: 74 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.211 | Train Acc: 92.53%\n",
      "\t Val. Loss: 0.482 |  Val. Acc: 85.96%\n",
      "Epoch: 75 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.207 | Train Acc: 92.64%\n",
      "\t Val. Loss: 0.662 |  Val. Acc: 82.77%\n",
      "Epoch: 76 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.207 | Train Acc: 92.67%\n",
      "\t Val. Loss: 0.511 |  Val. Acc: 84.38%\n",
      "Epoch: 77 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.199 | Train Acc: 92.92%\n",
      "\t Val. Loss: 0.503 |  Val. Acc: 85.51%\n",
      "Epoch: 78 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.201 | Train Acc: 92.85%\n",
      "\t Val. Loss: 0.464 |  Val. Acc: 85.82%\n",
      "Epoch: 79 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.200 | Train Acc: 92.96%\n",
      "\t Val. Loss: 0.500 |  Val. Acc: 85.61%\n",
      "Epoch: 80 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.196 | Train Acc: 93.05%\n",
      "\t Val. Loss: 0.632 |  Val. Acc: 83.48%\n",
      "Epoch: 81 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.193 | Train Acc: 93.26%\n",
      "\t Val. Loss: 0.508 |  Val. Acc: 84.96%\n",
      "Epoch: 82 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.190 | Train Acc: 93.28%\n",
      "\t Val. Loss: 0.494 |  Val. Acc: 85.61%\n",
      "Epoch: 83 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.188 | Train Acc: 93.30%\n",
      "\t Val. Loss: 0.622 |  Val. Acc: 84.04%\n",
      "Epoch: 84 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.185 | Train Acc: 93.39%\n",
      "\t Val. Loss: 0.521 |  Val. Acc: 84.90%\n",
      "Epoch: 85 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.57%\n",
      "\t Val. Loss: 0.459 |  Val. Acc: 86.13%\n",
      "Epoch: 86 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.55%\n",
      "\t Val. Loss: 0.481 |  Val. Acc: 86.48%\n",
      "Epoch: 87 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.56%\n",
      "\t Val. Loss: 0.558 |  Val. Acc: 84.65%\n",
      "Epoch: 88 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.181 | Train Acc: 93.55%\n",
      "\t Val. Loss: 0.526 |  Val. Acc: 84.73%\n",
      "Epoch: 89 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.62%\n",
      "\t Val. Loss: 0.483 |  Val. Acc: 85.94%\n",
      "Epoch: 90 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.87%\n",
      "\t Val. Loss: 0.482 |  Val. Acc: 86.35%\n",
      "Epoch: 91 | Epoch Time: 0m 29s\n",
      "\tTrain Loss: 0.170 | Train Acc: 93.92%\n",
      "\t Val. Loss: 0.558 |  Val. Acc: 84.55%\n",
      "Epoch: 92 | Epoch Time: 0m 28s\n",
      "\tTrain Loss: 0.170 | Train Acc: 94.03%\n",
      "\t Val. Loss: 0.481 |  Val. Acc: 86.56%\n",
      "Epoch: 93 | Epoch Time: 0m 29s\n",
      "\tTrain Loss: 0.167 | Train Acc: 94.09%\n",
      "\t Val. Loss: 0.545 |  Val. Acc: 85.25%\n",
      "Epoch: 94 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.171 | Train Acc: 93.78%\n",
      "\t Val. Loss: 0.550 |  Val. Acc: 85.78%\n",
      "Epoch: 95 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.172 | Train Acc: 93.81%\n",
      "\t Val. Loss: 0.603 |  Val. Acc: 84.86%\n",
      "Epoch: 96 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.166 | Train Acc: 94.04%\n",
      "\t Val. Loss: 0.571 |  Val. Acc: 84.98%\n",
      "Epoch: 97 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.158 | Train Acc: 94.36%\n",
      "\t Val. Loss: 0.509 |  Val. Acc: 86.17%\n",
      "Epoch: 98 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.164 | Train Acc: 94.12%\n",
      "\t Val. Loss: 0.521 |  Val. Acc: 86.07%\n",
      "Epoch: 99 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.161 | Train Acc: 94.18%\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 86.78%\n",
      "Epoch: 100 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.159 | Train Acc: 94.28%\n",
      "\t Val. Loss: 0.449 |  Val. Acc: 86.93%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "valid_acc_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "        \n",
    "    end_time = time.time()\n",
    "\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    train_acc_history.append(train_acc)\n",
    "    train_loss_history.append( train_loss)\n",
    "    valid_acc_history.append(valid_acc)\n",
    "    valid_loss_history.append(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'resnet20.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw3prob5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
